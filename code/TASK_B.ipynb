{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDA - Project 3\n",
    "## TASK B1: Activity detection\n",
    "This task consists of a binary classification, where a gesture denotes activity and thus the model detects wheter there is a gesture label or not (labeled in column 6).\n",
    "\n",
    "This first cell contains the parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- label_col: index of feature column to be selected to perform activity detection, between [0,6];\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "folder = \"./data/full/\"\n",
    "label = 0     # default for task B1\n",
    "window_size = 15\n",
    "stride = 5\n",
    "# make_binary = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import deeplearning\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  157125 \n",
      "Test samples:       57536 \n",
      "Features:             110\n",
      "\n",
      "TRAINING SET:\n",
      "Dataset of Images have shape:  (31422, 15, 110) \n",
      "Dataset of Labels have shape:    (31422, 2) \n",
      "Fraction of labels:   [0.11036853 0.88963147]\n",
      "\n",
      "TEST SET:\n",
      "Dataset of Images have shape:  (11504, 15, 110) \n",
      "Dataset of Labels have shape:    (11504, 2) \n",
      "Fraction of labels:   [0.1772427 0.8227573]\n"
     ]
    }
   ],
   "source": [
    "[x_train, y_train, x_test, y_test, n_classes] = utils.preprocessing(subject,\n",
    "                                                                    folder,\n",
    "                                                                    label,\n",
    "                                                                    window_size,\n",
    "                                                                    stride,\n",
    "                                                                    printInfo = True,\n",
    "                                                                    make_binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of data in a input-suitable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 15, 110, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 108, 50)        1700      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 108, 50)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2, 5400)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 2, 20)             433680    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               10752     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 450,442\n",
      "Trainable params: 450,440\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_features = 110 #number of features taken into consideration for the solution of the problem\n",
    "n_classes = 2\n",
    "\n",
    "detection_model = deeplearning.MotionDetection((window_size,n_features,1), n_classes)\n",
    "detection_model.summary() # model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31422 samples, validate on 11504 samples\n",
      "Epoch 1/20\n",
      "31422/31422 [==============================] - 10s 321us/step - loss: 0.1696 - acc: 0.9424 - val_loss: 0.3189 - val_acc: 0.8964\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31890, saving model to ./data/weights_d.hdf5\n",
      "Epoch 2/20\n",
      "31422/31422 [==============================] - 7s 227us/step - loss: 0.1556 - acc: 0.9490 - val_loss: 0.1909 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31890 to 0.19087, saving model to ./data/weights_d.hdf5\n",
      "Epoch 3/20\n",
      "31422/31422 [==============================] - 7s 224us/step - loss: 0.1502 - acc: 0.9513 - val_loss: 0.1959 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/20\n",
      "31422/31422 [==============================] - 7s 221us/step - loss: 0.1375 - acc: 0.9557 - val_loss: 0.2182 - val_acc: 0.9335\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/20\n",
      "31422/31422 [==============================] - 7s 219us/step - loss: 0.1536 - acc: 0.9462 - val_loss: 0.3091 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "31422/31422 [==============================] - 7s 215us/step - loss: 0.1411 - acc: 0.9552 - val_loss: 0.1996 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/20\n",
      "31422/31422 [==============================] - 7s 220us/step - loss: 0.1410 - acc: 0.9536 - val_loss: 0.2020 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "31422/31422 [==============================] - 7s 222us/step - loss: 0.1319 - acc: 0.9577 - val_loss: 0.1939 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "31422/31422 [==============================] - 7s 222us/step - loss: 0.1352 - acc: 0.9553 - val_loss: 0.1783 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19087 to 0.17830, saving model to ./data/weights_d.hdf5\n",
      "Epoch 10/20\n",
      "31422/31422 [==============================] - 7s 220us/step - loss: 0.1496 - acc: 0.9508 - val_loss: 0.2833 - val_acc: 0.8933\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "31422/31422 [==============================] - 7s 227us/step - loss: 0.1681 - acc: 0.9460 - val_loss: 0.2940 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "31422/31422 [==============================] - 7s 216us/step - loss: 0.1474 - acc: 0.9539 - val_loss: 0.2355 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "31422/31422 [==============================] - 7s 213us/step - loss: 0.1541 - acc: 0.9503 - val_loss: 0.3225 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "31422/31422 [==============================] - 7s 212us/step - loss: 0.1628 - acc: 0.9438 - val_loss: 0.2479 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "31422/31422 [==============================] - 7s 213us/step - loss: 0.1578 - acc: 0.9477 - val_loss: 0.2383 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "31422/31422 [==============================] - 7s 211us/step - loss: 0.1520 - acc: 0.9474 - val_loss: 0.2808 - val_acc: 0.8925\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "31422/31422 [==============================] - 7s 211us/step - loss: 0.1470 - acc: 0.9518 - val_loss: 0.2159 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "31422/31422 [==============================] - 7s 213us/step - loss: 0.1340 - acc: 0.9616 - val_loss: 0.2053 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "31422/31422 [==============================] - 7s 213us/step - loss: 0.1523 - acc: 0.9529 - val_loss: 0.3414 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "31422/31422 [==============================] - 7s 211us/step - loss: 0.1550 - acc: 0.9535 - val_loss: 0.2170 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18424624390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.compile(optimizer = Adam(lr=0.01), \n",
    "                        loss = \"categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\"])\n",
    "\n",
    "input_train = x_train.reshape(x_train.shape[0], window_size, n_features, 1)\n",
    "input_test = x_test.reshape(x_test.shape[0], window_size, n_features, 1)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./data/weights_d.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "detection_model.fit(x = input_train, \n",
    "                    y = y_train, \n",
    "                    epochs = 20, \n",
    "                    batch_size = 128,\n",
    "                    verbose = 1,\n",
    "                    validation_data=(input_test, y_test),\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.61      0.75      2039\n",
      "          1       0.92      0.99      0.96      9465\n",
      "\n",
      "avg / total       0.93      0.93      0.92     11504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = detection_model.predict(input_test)\n",
    "y_pred = np.argmax(y_pred, 1)\n",
    "\n",
    "print(classification_report(y_test, to_categorical(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.78      0.82      2039\n",
      "          1       0.95      0.97      0.96      9465\n",
      "\n",
      "avg / total       0.94      0.94      0.94     11504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detection_model_best = load_model('./data/weights_d.hdf5')\n",
    "\n",
    "y_pred = detection_model_best.predict(input_test)\n",
    "y_pred = np.argmax(y_pred, 1)\n",
    "\n",
    "print(classification_report(y_test, to_categorical(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B2: gesture recognition\n",
    "This task consists of a 17-class classification, where gestures are labeled in column 6.\n",
    "\n",
    "To tune the following parameters, refer to the first cell of task B1:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- label_col: index of feature column to be selected to perform activity detection, between [0,6];\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window.\n",
    "\n",
    "Here we just need to preserve the different labels, thus we set 'make_binary' to False. We have then 18 different labels, keeping into account the null class, with label 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  157125 \n",
      "Test samples:       57536 \n",
      "Features:             110\n",
      "\n",
      "TRAINING SET:\n",
      "Dataset of Images have shape:  (27948, 15, 110) \n",
      "Dataset of Labels have shape:    (27948, 4) \n",
      "Fraction of labels:   [0.47098182 0.30918134 0.19253614 0.0273007 ]\n",
      "\n",
      "TEST SET:\n",
      "Dataset of Images have shape:  (9465, 15, 110) \n",
      "Dataset of Labels have shape:    (9465, 4) \n",
      "Fraction of labels:   [0.41817221 0.24638141 0.28874802 0.04669836]\n"
     ]
    }
   ],
   "source": [
    "[x_train, y_train, x_test, y_test, n_classes] = utils.preprocessing(subject,\n",
    "                                                                    folder,\n",
    "                                                                    label,\n",
    "                                                                    window_size,\n",
    "                                                                    stride,\n",
    "                                                                    printInfo = True,\n",
    "                                                                    make_binary = False,\n",
    "                                                                    null_class = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4 # OVERWRITE TO BE FIXED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 15, 110, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 110, 50)        600       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 110, 50)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2, 5500)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 2, 300)            6961200   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 7,839,168\n",
      "Trainable params: 7,839,166\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = deeplearning.MotionClassification((window_size,n_features,1), n_classes)\n",
    "classification_model.summary() # model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27948 samples, validate on 9465 samples\n",
      "Epoch 1/20\n",
      "27948/27948 [==============================] - 18s 642us/step - loss: 0.3299 - acc: 0.8682 - val_loss: 0.2760 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27595, saving model to ./data/weights_c.hdf5\n",
      "Epoch 2/20\n",
      "27948/27948 [==============================] - 14s 508us/step - loss: 0.2626 - acc: 0.8954 - val_loss: 0.2920 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.2445 - acc: 0.9036 - val_loss: 0.2598 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27595 to 0.25982, saving model to ./data/weights_c.hdf5\n",
      "Epoch 4/20\n",
      "27948/27948 [==============================] - 14s 510us/step - loss: 0.2449 - acc: 0.9025 - val_loss: 0.2759 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.2448 - acc: 0.9043 - val_loss: 0.2952 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.2455 - acc: 0.9014 - val_loss: 0.2647 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.2502 - acc: 0.8993 - val_loss: 0.2185 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25982 to 0.21853, saving model to ./data/weights_c.hdf5\n",
      "Epoch 8/20\n",
      "27948/27948 [==============================] - 14s 510us/step - loss: 0.2549 - acc: 0.9000 - val_loss: 0.3052 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.2812 - acc: 0.8888 - val_loss: 0.2479 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "27948/27948 [==============================] - 14s 511us/step - loss: 0.3279 - acc: 0.8762 - val_loss: 0.2854 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "27948/27948 [==============================] - 14s 510us/step - loss: 0.2802 - acc: 0.8899 - val_loss: 0.1848 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.21853 to 0.18484, saving model to ./data/weights_c.hdf5\n",
      "Epoch 12/20\n",
      "27948/27948 [==============================] - 14s 511us/step - loss: 0.2871 - acc: 0.8841 - val_loss: 0.3102 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "27948/27948 [==============================] - 14s 510us/step - loss: 0.2742 - acc: 0.8895 - val_loss: 0.3210 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.2894 - acc: 0.8833 - val_loss: 0.3009 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.2927 - acc: 0.8846 - val_loss: 0.3243 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.3055 - acc: 0.8775 - val_loss: 0.3617 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "27948/27948 [==============================] - 14s 509us/step - loss: 0.3003 - acc: 0.8819 - val_loss: 0.2993 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "27948/27948 [==============================] - 14s 514us/step - loss: 0.3021 - acc: 0.8787 - val_loss: 0.3433 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "27948/27948 [==============================] - 14s 510us/step - loss: 0.2869 - acc: 0.8858 - val_loss: 0.2920 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "27948/27948 [==============================] - 14s 508us/step - loss: 0.2820 - acc: 0.8864 - val_loss: 0.3374 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185507bcdd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.compile(optimizer = Adam(lr=0.01), \n",
    "                             loss = \"categorical_crossentropy\", \n",
    "                             metrics = [\"accuracy\"])\n",
    "\n",
    "input_train = x_train.reshape(x_train.shape[0], window_size, n_features, 1)\n",
    "input_test = x_test.reshape(x_test.shape[0], window_size, n_features, 1)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./data/weights_c.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "classification_model.fit(x = input_train, \n",
    "                         y = y_train, \n",
    "                         epochs = 20, \n",
    "                         batch_size = 128,\n",
    "                         verbose = 1,\n",
    "                         validation_data=(input_test, y_test),\n",
    "                         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91      3958\n",
      "          1       0.88      0.87      0.87      2332\n",
      "          2       0.98      1.00      0.99      2733\n",
      "          3       1.00      0.85      0.92       442\n",
      "\n",
      "avg / total       0.93      0.93      0.93      9465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classification_model.predict(input_test)\n",
    "y_pred = np.argmax(y_pred, 1)\n",
    "\n",
    "print(classification_report(y_test, to_categorical(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91      3958\n",
      "          1       0.82      0.91      0.87      2332\n",
      "          2       0.99      1.00      0.99      2733\n",
      "          3       0.99      1.00      0.99       442\n",
      "\n",
      "avg / total       0.93      0.93      0.93      9465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detection_model_best = load_model('./data/weights_c.hdf5')\n",
    "\n",
    "y_pred = detection_model_best.predict(input_test)\n",
    "y_pred = np.argmax(y_pred, 1)\n",
    "\n",
    "print(classification_report(y_test, to_categorical(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with null class\n",
    "(detection and classification are performed together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  157125 \n",
      "Test samples:       57536 \n",
      "Features:             110\n",
      "\n",
      "TRAINING SET:\n",
      "Dataset of Images have shape:  (31422, 15, 110) \n",
      "Dataset of Labels have shape:    (31422, 5) \n",
      "Fraction of labels:   [0.11055948 0.41891032 0.27499841 0.17124944 0.02428235]\n",
      "\n",
      "TEST SET:\n",
      "Dataset of Images have shape:  (11504, 15, 110) \n",
      "Dataset of Labels have shape:    (11504, 5) \n",
      "Fraction of labels:   [0.1772427  0.34405424 0.2027121  0.23756954 0.03842142]\n"
     ]
    }
   ],
   "source": [
    "[x_train, y_train, x_test, y_test, n_classes] = utils.preprocessing(subject,\n",
    "                                                                    folder,\n",
    "                                                                    label,\n",
    "                                                                    window_size,\n",
    "                                                                    stride,\n",
    "                                                                    printInfo = True,\n",
    "                                                                    make_binary = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 15, 110, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 110, 50)        600       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 110, 50)        0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 2, 5500)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 2, 300)            6961200   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 7,839,681\n",
      "Trainable params: 7,839,679\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = deeplearning.MotionClassification((window_size,n_features,1), n_classes)\n",
    "classification_model.summary() # model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31422 samples, validate on 11504 samples\n",
      "Epoch 1/20\n",
      "31422/31422 [==============================] - 16s 507us/step - loss: 0.4319 - acc: 0.8369 - val_loss: 0.3271 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32708, saving model to ./data/weights_dc.hdf5\n",
      "Epoch 2/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.2585 - acc: 0.9024 - val_loss: 0.3647 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.2248 - acc: 0.9164 - val_loss: 0.3365 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.2091 - acc: 0.9233 - val_loss: 0.4733 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.1807 - acc: 0.9325 - val_loss: 0.3538 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "31422/31422 [==============================] - 11s 345us/step - loss: 0.1624 - acc: 0.9394 - val_loss: 0.2956 - val_acc: 0.8972\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32708 to 0.29561, saving model to ./data/weights_dc.hdf5\n",
      "Epoch 7/20\n",
      "31422/31422 [==============================] - 11s 345us/step - loss: 0.1520 - acc: 0.9430 - val_loss: 0.4144 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "31422/31422 [==============================] - 11s 346us/step - loss: 0.1388 - acc: 0.9479 - val_loss: 0.4801 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "31422/31422 [==============================] - 11s 345us/step - loss: 0.1390 - acc: 0.9487 - val_loss: 0.4439 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "31422/31422 [==============================] - 11s 345us/step - loss: 0.1357 - acc: 0.9497 - val_loss: 0.4966 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.1311 - acc: 0.9552 - val_loss: 0.4968 - val_acc: 0.8974\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.1162 - acc: 0.9571 - val_loss: 0.5400 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "31422/31422 [==============================] - 11s 343us/step - loss: 0.1079 - acc: 0.9618 - val_loss: 0.4929 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "31422/31422 [==============================] - 11s 343us/step - loss: 0.1003 - acc: 0.9649 - val_loss: 0.5239 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "31422/31422 [==============================] - 11s 343us/step - loss: 0.1012 - acc: 0.9651 - val_loss: 0.5677 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "31422/31422 [==============================] - 11s 343us/step - loss: 0.0935 - acc: 0.9665 - val_loss: 0.5015 - val_acc: 0.8962\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.0825 - acc: 0.9704 - val_loss: 0.5687 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.0828 - acc: 0.9699 - val_loss: 0.6413 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "31422/31422 [==============================] - 11s 345us/step - loss: 0.0949 - acc: 0.9693 - val_loss: 0.5253 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "31422/31422 [==============================] - 11s 344us/step - loss: 0.0818 - acc: 0.9703 - val_loss: 0.6671 - val_acc: 0.8946\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18449938b70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.compile(optimizer = Adam(lr=0.01), \n",
    "                             loss = \"categorical_crossentropy\", \n",
    "                             metrics = [\"accuracy\"])\n",
    "\n",
    "input_train = x_train.reshape(x_train.shape[0], window_size, n_features, 1)\n",
    "input_test = x_test.reshape(x_test.shape[0], window_size, n_features, 1)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./data/weights_dc.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "classification_model.fit(x = input_train, \n",
    "                         y = y_train, \n",
    "                         epochs = 20, \n",
    "                         batch_size = 300,\n",
    "                         verbose = 1,\n",
    "                         validation_data=(input_test, y_test),\n",
    "                         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.80      0.84      2039\n",
      "          1       0.91      0.90      0.91      3958\n",
      "          2       0.78      0.86      0.82      2332\n",
      "          3       0.98      0.99      0.99      2733\n",
      "          4       0.90      0.85      0.87       442\n",
      "\n",
      "avg / total       0.90      0.89      0.89     11504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classification_model.predict(input_test)\n",
    "y_pred = np.argmax(y_pred, 1)\n",
    "\n",
    "print(classification_report(y_test, to_categorical(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86      2039\n",
      "          1       0.92      0.90      0.91      3958\n",
      "          2       0.79      0.84      0.81      2332\n",
      "          3       0.98      1.00      0.99      2733\n",
      "          4       0.97      0.82      0.89       442\n",
      "\n",
      "avg / total       0.90      0.90      0.90     11504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_model_best = load_model('./data/weights_dc.hdf5')\n",
    "\n",
    "y_pred = classification_model_best.predict(input_test)\n",
    "y_pred = np.argmax(y_pred, 1)\n",
    "\n",
    "print(classification_report(y_test, to_categorical(y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
