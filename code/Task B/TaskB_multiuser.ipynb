{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B - single subject - model ?\n",
    "\n",
    "## Notebook setup\n",
    "This first cell contains the parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- label: index of feature column to be selected to perform activity detection, between [0,6]. The default value for task B is 6;\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 6\n",
    "folder = \"../data/full/\"\n",
    "window_size = 15\n",
    "stride = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "import models\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not(os.path.exists(\"./data\")):\n",
    "    os.mkdir(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot classification\n",
    "Here classification is performed with null class.\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data from subject 1\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.66779111 0.01365242 0.01473443 0.01120199 0.02020813 0.02074913\n",
      " 0.01183846 0.01613468 0.01307959 0.01377972 0.01584826 0.01225217\n",
      " 0.02132196 0.02199026 0.01152022 0.01724851 0.07889126 0.01775769]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.77548892 0.00764885 0.00591047 0.00808344 0.01425467 0.01156019\n",
      " 0.00365059 0.01833985 0.00990874 0.0065189  0.00808344 0.00582355\n",
      " 0.01642764 0.01399392 0.00295524 0.01521078 0.06996958 0.00617123]\n",
      "\n",
      "Processing data from subject 2\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (38733, 110)\n",
      "ADL2:   (26824, 110)\n",
      "ADL3:   (31242, 110)\n",
      "ADL4:   (29723, 110)\n",
      "ADL5:   (27997, 110)\n",
      "Drill:  (49009, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.6284852  0.01879351 0.01416372 0.00823073 0.0201996  0.02157138\n",
      " 0.00956823 0.02249734 0.01831339 0.02222298 0.01265475 0.01063137\n",
      " 0.01978806 0.01913646 0.0143009  0.02493227 0.08103844 0.03347166]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.8403223  0.00935713 0.00658465 0.00294576 0.00441864 0.00944377\n",
      " 0.0030324  0.0183677  0.01031017 0.01221625 0.00641137 0.00407208\n",
      " 0.00537169 0.00953041 0.00441864 0.02269971 0.01602842 0.0144689 ]\n",
      "\n",
      "Processing data from subject 3\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32340, 110)\n",
      "ADL2:   (24918, 110)\n",
      "ADL3:   (24395, 110)\n",
      "ADL4:   (25169, 110)\n",
      "ADL5:   (23836, 110)\n",
      "Drill:  (68445, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.65879335 0.01522471 0.01389213 0.01096046 0.01868941 0.02045508\n",
      " 0.01069394 0.02238731 0.01552454 0.01502482 0.01339241 0.01182663\n",
      " 0.02152114 0.02395309 0.01192657 0.02571876 0.07115968 0.01885598]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.78252883 0.0081641  0.00704153 0.00326564 0.00928666 0.00908256\n",
      " 0.00704153 0.01745076 0.01387897 0.00989897 0.0085723  0.00510256\n",
      " 0.00734769 0.01193999 0.00428615 0.0290846  0.05867946 0.00734769]\n",
      "\n",
      "Processing data from subject 4\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32076, 110)\n",
      "ADL2:   (23717, 110)\n",
      "ADL3:   (20794, 110)\n",
      "ADL4:   (18668, 110)\n",
      "ADL5:   (27007, 110)\n",
      "Drill:  (41906, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.64905469 0.01612086 0.01240716 0.01008609 0.01911715 0.01996117\n",
      " 0.00915766 0.02536293 0.01341999 0.01768231 0.01295577 0.01114112\n",
      " 0.01928596 0.01966577 0.01266036 0.02553174 0.07866307 0.0277262 ]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.78364174 0.0047082  0.00766451 0.00667908 0.01500055 0.00821198\n",
      " 0.00656958 0.02310303 0.01302967 0.00503668 0.00810249 0.00656958\n",
      " 0.0188328  0.01237271 0.00897843 0.02091317 0.03043907 0.02014672]\n",
      "\n",
      "Shapes: \n",
      "X_train:  (114295, 15, 110) \n",
      "Y_train:  (114295,) \n",
      "X_test:  (41979, 15, 110) \n",
      "Y_test:  (41979,)\n",
      "\n",
      "Class weights:\n",
      " [0.08527123 3.49654307 4.00108521 5.47389847 2.83723066 2.68147053\n",
      " 5.34038875 2.60661832 3.67248249 3.25459878 4.02901156 4.8323609\n",
      " 2.70200946 2.60876016 4.41873502 2.39974385 0.7181319  2.30312739]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadDataMultiple(label=label,\n",
    "                                                                                                        folder=folder,\n",
    "                                                                                                        window_size=window_size,\n",
    "                                                                                                        stride=stride,\n",
    "                                                                                                        make_binary=False,\n",
    "                                                                                                        null_class=True,\n",
    "                                                                                                        print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train and Y_test contain the correct labels for each signals window. Y_test in particular will be used to evaluate predictions for both this (one-shot) and the two-steps models. For this reason it is here saved with a different name, to avoid having it being overwritten later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_true = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_model = models.MotionDetection((window_size, n_features), n_classes, print_info=False)\n",
    "\n",
    "oneshot_model.compile(optimizer = Adam(lr=0.001),\n",
    "                      loss = \"categorical_crossentropy\", \n",
    "                      metrics = [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model_OS_1.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114295, 15, 110)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114295 samples, validate on 41979 samples\n",
      "Epoch 1/15\n",
      "114295/114295 [==============================] - 227s 2ms/step - loss: 0.7769 - acc: 0.7610 - val_loss: 0.5208 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52084, saving model to ./model_OS_1.hdf5\n",
      "Epoch 2/15\n",
      "114295/114295 [==============================] - 223s 2ms/step - loss: 0.5758 - acc: 0.8142 - val_loss: 0.5115 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52084 to 0.51155, saving model to ./model_OS_1.hdf5\n",
      "Epoch 3/15\n",
      "114295/114295 [==============================] - 222s 2ms/step - loss: 0.5145 - acc: 0.8323 - val_loss: 0.5187 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/15\n",
      "114295/114295 [==============================] - 239s 2ms/step - loss: 0.4802 - acc: 0.8411 - val_loss: 0.5122 - val_acc: 0.8541\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4629 - acc: 0.8460 - val_loss: 0.5224 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4485 - acc: 0.8511 - val_loss: 0.5069 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51155 to 0.50688, saving model to ./model_OS_1.hdf5\n",
      "Epoch 7/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4354 - acc: 0.8551 - val_loss: 0.5387 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4283 - acc: 0.8563 - val_loss: 0.5265 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4205 - acc: 0.8594 - val_loss: 0.5330 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4180 - acc: 0.8612 - val_loss: 0.5455 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4144 - acc: 0.8616 - val_loss: 0.5387 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4135 - acc: 0.8616 - val_loss: 0.5385 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4078 - acc: 0.8625 - val_loss: 0.5354 - val_acc: 0.8521\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4058 - acc: 0.8641 - val_loss: 0.5328 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.4036 - acc: 0.8648 - val_loss: 0.5317 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e11b6ff28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneshot_model.fit(x = X_train, \n",
    "                  y = to_categorical(Y_train),\n",
    "                  epochs = 15,\n",
    "                  batch_size = 16,\n",
    "                  verbose = 1,\n",
    "                  callbacks=[checkpointer],\n",
    "                  validation_data=(X_test, to_categorical(Y_test)),\n",
    "                  class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - passare class_weights a class report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.95      0.93     33446\n",
      "          1       0.33      0.32      0.33       319\n",
      "          2       0.38      0.47      0.42       283\n",
      "          3       0.36      0.15      0.21       220\n",
      "          4       0.69      0.61      0.65       443\n",
      "          5       0.65      0.71      0.68       406\n",
      "          6       0.33      0.32      0.32       206\n",
      "          7       0.54      0.49      0.51       805\n",
      "          8       0.42      0.45      0.43       488\n",
      "          9       0.57      0.20      0.30       359\n",
      "         10       0.41      0.46      0.43       325\n",
      "         11       0.34      0.16      0.21       224\n",
      "         12       0.56      0.58      0.57       495\n",
      "         13       0.71      0.64      0.67       501\n",
      "         14       0.37      0.22      0.27       209\n",
      "         15       0.62      0.34      0.44       913\n",
      "         16       0.77      0.63      0.69      1843\n",
      "         17       0.64      0.41      0.50       494\n",
      "\n",
      "avg / total       0.85      0.86      0.85     41979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = oneshot_model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.93     33446\n",
      "          1       0.45      0.37      0.41       319\n",
      "          2       0.41      0.39      0.40       283\n",
      "          3       0.30      0.35      0.33       220\n",
      "          4       0.74      0.63      0.68       443\n",
      "          5       0.73      0.60      0.66       406\n",
      "          6       0.37      0.27      0.31       206\n",
      "          7       0.65      0.45      0.53       805\n",
      "          8       0.51      0.55      0.53       488\n",
      "          9       0.29      0.26      0.27       359\n",
      "         10       0.51      0.27      0.35       325\n",
      "         11       0.26      0.18      0.21       224\n",
      "         12       0.58      0.63      0.61       495\n",
      "         13       0.59      0.71      0.64       501\n",
      "         14       0.25      0.33      0.29       209\n",
      "         15       0.59      0.38      0.46       913\n",
      "         16       0.72      0.66      0.69      1843\n",
      "         17       0.60      0.45      0.51       494\n",
      "\n",
      "avg / total       0.85      0.85      0.85     41979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneshot_model_best = load_model('./model_OS_1.hdf5')\n",
    "\n",
    "Y_pred = oneshot_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-steps classification\n",
    "## Activity detection\n",
    "This model performs a binary classification.\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data from subject 1\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.66718646 0.33281354]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.775402 0.224598]\n",
      "\n",
      "Processing data from subject 2\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (38733, 110)\n",
      "ADL2:   (26824, 110)\n",
      "ADL3:   (31242, 110)\n",
      "ADL4:   (29723, 110)\n",
      "ADL5:   (27997, 110)\n",
      "Drill:  (49009, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.62755924 0.37244076]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.84014902 0.15985098]\n",
      "\n",
      "Processing data from subject 3\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32340, 110)\n",
      "ADL2:   (24918, 110)\n",
      "ADL3:   (24395, 110)\n",
      "ADL4:   (25169, 110)\n",
      "ADL5:   (23836, 110)\n",
      "Drill:  (68445, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.65866009 0.34133991]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.78252883 0.21747117]\n",
      "\n",
      "Processing data from subject 4\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32076, 110)\n",
      "ADL2:   (23717, 110)\n",
      "ADL3:   (20794, 110)\n",
      "ADL4:   (18668, 110)\n",
      "ADL5:   (27007, 110)\n",
      "Drill:  (41906, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.64774646 0.35225354]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.78342275 0.21657725]\n",
      "\n",
      "Shapes: \n",
      "X_train:  (114295, 15, 110) \n",
      "Y_train:  (114295,) \n",
      "X_test:  (41979, 15, 110) \n",
      "Y_test:  (41979,)\n",
      "\n",
      "Class weights:\n",
      " [0.76827678 1.43187342]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadDataMultiple(label=label,\n",
    "                                                                                                        folder=folder,\n",
    "                                                                                                        window_size=window_size,\n",
    "                                                                                                        stride=stride,\n",
    "                                                                                                        make_binary=True,\n",
    "                                                                                                        null_class=True,\n",
    "                                                                                                        print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = models.MotionDetection((window_size, n_features), n_classes, print_info=False)\n",
    "\n",
    "detection_model.compile(optimizer = Adam(lr=0.001),\n",
    "                        loss = \"categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model_TSD_1.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114295 samples, validate on 41979 samples\n",
      "Epoch 1/15\n",
      "114295/114295 [==============================] - 223s 2ms/step - loss: 0.3653 - acc: 0.8357 - val_loss: 0.3129 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31285, saving model to ./model_TSD_1.hdf5\n",
      "Epoch 2/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.3003 - acc: 0.8677 - val_loss: 0.2811 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31285 to 0.28108, saving model to ./model_TSD_1.hdf5\n",
      "Epoch 3/15\n",
      "114295/114295 [==============================] - 219s 2ms/step - loss: 0.2792 - acc: 0.8772 - val_loss: 0.2957 - val_acc: 0.8768\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/15\n",
      "114295/114295 [==============================] - 219s 2ms/step - loss: 0.2679 - acc: 0.8826 - val_loss: 0.2736 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28108 to 0.27358, saving model to ./model_TSD_1.hdf5\n",
      "Epoch 5/15\n",
      "114295/114295 [==============================] - 220s 2ms/step - loss: 0.2573 - acc: 0.8890 - val_loss: 0.2788 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/15\n",
      "114295/114295 [==============================] - 220s 2ms/step - loss: 0.2524 - acc: 0.8902 - val_loss: 0.3222 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/15\n",
      "114295/114295 [==============================] - 220s 2ms/step - loss: 0.2464 - acc: 0.8938 - val_loss: 0.2797 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/15\n",
      "114295/114295 [==============================] - 222s 2ms/step - loss: 0.2447 - acc: 0.8937 - val_loss: 0.2762 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.2428 - acc: 0.8950 - val_loss: 0.2842 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/15\n",
      "114295/114295 [==============================] - 222s 2ms/step - loss: 0.2403 - acc: 0.8959 - val_loss: 0.2922 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.2366 - acc: 0.8973 - val_loss: 0.2854 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.2351 - acc: 0.8997 - val_loss: 0.2848 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/15\n",
      "114295/114295 [==============================] - 222s 2ms/step - loss: 0.2350 - acc: 0.8983 - val_loss: 0.2947 - val_acc: 0.8845\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/15\n",
      "114295/114295 [==============================] - 221s 2ms/step - loss: 0.2331 - acc: 0.8990 - val_loss: 0.2911 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/15\n",
      "114295/114295 [==============================] - 222s 2ms/step - loss: 0.2331 - acc: 0.8983 - val_loss: 0.2928 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e7fa59748>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.fit(x = X_train, \n",
    "                    y = to_categorical(Y_train), \n",
    "                    epochs = 15, \n",
    "                    batch_size = 16,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[checkpointer],\n",
    "                    validation_data=(X_test, to_categorical(Y_test)),\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93     33441\n",
      "          1       0.73      0.72      0.72      8538\n",
      "\n",
      "avg / total       0.89      0.89      0.89     41979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = detection_model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.94      0.93     33441\n",
      "          1       0.73      0.69      0.71      8538\n",
      "\n",
      "avg / total       0.88      0.89      0.89     41979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detection_model_best = load_model('./model_TSD_1.hdf5')\n",
    "\n",
    "Y_pred = detection_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_d = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data from subject 1\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.04109589 0.04435291 0.0337197  0.06082958 0.06245809 0.0356356\n",
      " 0.04856787 0.03937159 0.04147907 0.04770572 0.03688093 0.06418239\n",
      " 0.06619408 0.03467765 0.05192068 0.23747485 0.0534534 ]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.03406891 0.02632598 0.03600465 0.06349206 0.05149051 0.01626016\n",
      " 0.08168796 0.04413473 0.029036   0.03600465 0.02593883 0.07317073\n",
      " 0.06233062 0.01316299 0.06775068 0.31165312 0.02748742]\n",
      "\n",
      "Processing data from subject 2\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (38733, 110)\n",
      "ADL2:   (26824, 110)\n",
      "ADL3:   (31242, 110)\n",
      "ADL4:   (29723, 110)\n",
      "ADL5:   (27997, 110)\n",
      "Drill:  (49009, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.05058617 0.03812425 0.02215453 0.0543709  0.05806333 0.02575464\n",
      " 0.06055571 0.04929382 0.05981723 0.03406259 0.02861627 0.05326318\n",
      " 0.05150928 0.03849349 0.06710976 0.21812979 0.09009508]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.05860011 0.04123711 0.01844818 0.02767227 0.0591427  0.01899078\n",
      " 0.11502984 0.06456864 0.0765057  0.04015193 0.0255019  0.0336408\n",
      " 0.0596853  0.02767227 0.14215952 0.10037982 0.09061313]\n",
      "\n",
      "Processing data from subject 3\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32340, 110)\n",
      "ADL2:   (24918, 110)\n",
      "ADL3:   (24395, 110)\n",
      "ADL4:   (25169, 110)\n",
      "ADL5:   (23836, 110)\n",
      "Drill:  (68445, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.04462019 0.0407147  0.03212263 0.05477446 0.05994923 0.03134153\n",
      " 0.06561219 0.04549893 0.04403437 0.03925015 0.0346612  0.06307362\n",
      " 0.07020113 0.03495411 0.0753759  0.20855302 0.05526264]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.03754106 0.03237916 0.01501642 0.04270296 0.04176443 0.03237916\n",
      " 0.08024402 0.0638198  0.04551854 0.03941811 0.02346316 0.03378695\n",
      " 0.0549038  0.01970906 0.13374003 0.26982637 0.03378695]\n",
      "\n",
      "Processing data from subject 4\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32076, 110)\n",
      "ADL2:   (23717, 110)\n",
      "ADL3:   (20794, 110)\n",
      "ADL4:   (18668, 110)\n",
      "ADL5:   (27007, 110)\n",
      "Drill:  (41906, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.04593555 0.03535354 0.02873978 0.0544733  0.05687831 0.02609428\n",
      " 0.07227032 0.03823954 0.0503848  0.03691679 0.03174603 0.0549543\n",
      " 0.05603656 0.03607504 0.07275132 0.22414622 0.07900433]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.02176113 0.0354251  0.03087045 0.06933198 0.03795547 0.03036437\n",
      " 0.10678138 0.06022267 0.02327935 0.03744939 0.03036437 0.08704453\n",
      " 0.05718623 0.04149798 0.09665992 0.14068826 0.09311741]\n",
      "\n",
      "Shapes: \n",
      "X_train:  (39830, 15, 110) \n",
      "Y_train:  (39830,) \n",
      "X_test:  (8533, 15, 110) \n",
      "Y_test:  (8533,)\n",
      "\n",
      "Class weights:\n",
      " [1.29016585 1.47633344 2.01977688 1.04689061 0.98941773 1.97051403\n",
      " 0.96179851 1.35508454 1.20089245 1.4866378  1.78306026 0.99699625\n",
      " 0.96258882 1.63043923 0.8854653  0.26497864 0.84981544]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadDataMultiple(label=label,\n",
    "                                                                                                        folder=folder,\n",
    "                                                                                                        window_size=window_size,\n",
    "                                                                                                        stride=stride,\n",
    "                                                                                                        make_binary=False,\n",
    "                                                                                                        null_class=False,\n",
    "                                                                                                        print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = models.MotionDetection((window_size, n_features), n_classes, print_info=False)\n",
    "\n",
    "classification_model.compile(optimizer = Adam(lr=0.001),\n",
    "                             loss = \"categorical_crossentropy\", \n",
    "                             metrics = [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model_TSC_1.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39830 samples, validate on 8533 samples\n",
      "Epoch 1/15\n",
      "39830/39830 [==============================] - 80s 2ms/step - loss: 1.1114 - acc: 0.6115 - val_loss: 1.1875 - val_acc: 0.6192\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.18751, saving model to ./model_TSC_1.hdf5\n",
      "Epoch 2/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.7364 - acc: 0.7444 - val_loss: 1.1274 - val_acc: 0.6456\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.18751 to 1.12737, saving model to ./model_TSC_1.hdf5\n",
      "Epoch 3/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.6146 - acc: 0.7842 - val_loss: 1.1410 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.5420 - acc: 0.8109 - val_loss: 1.1856 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.4903 - acc: 0.8274 - val_loss: 1.1980 - val_acc: 0.6689\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.4597 - acc: 0.8377 - val_loss: 1.2894 - val_acc: 0.6640\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.4350 - acc: 0.8461 - val_loss: 1.2594 - val_acc: 0.6707\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.4179 - acc: 0.8539 - val_loss: 1.3110 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.3996 - acc: 0.8595 - val_loss: 1.3233 - val_acc: 0.6683\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.3935 - acc: 0.8618 - val_loss: 1.2434 - val_acc: 0.6719\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.3835 - acc: 0.8642 - val_loss: 1.2572 - val_acc: 0.6822\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.3669 - acc: 0.8695 - val_loss: 1.3744 - val_acc: 0.6747\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.3613 - acc: 0.8713 - val_loss: 1.3676 - val_acc: 0.6710\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.3573 - acc: 0.8754 - val_loss: 1.3695 - val_acc: 0.6728\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/15\n",
      "39830/39830 [==============================] - 76s 2ms/step - loss: 0.3492 - acc: 0.8757 - val_loss: 1.3552 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ec459c908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(x = X_train,\n",
    "                         y = to_categorical(Y_train), \n",
    "                         epochs = 15, \n",
    "                         batch_size = 16,\n",
    "                         verbose = 1,\n",
    "                         callbacks=[checkpointer],\n",
    "                         validation_data=(X_test, to_categorical(Y_test)),\n",
    "                         class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.53      0.52       319\n",
      "          1       0.59      0.48      0.53       283\n",
      "          2       0.35      0.17      0.23       220\n",
      "          3       0.66      0.74      0.70       443\n",
      "          4       0.69      0.85      0.77       406\n",
      "          5       0.42      0.43      0.43       206\n",
      "          6       0.64      0.72      0.68       805\n",
      "          7       0.62      0.73      0.67       488\n",
      "          8       0.49      0.43      0.46       359\n",
      "          9       0.58      0.40      0.47       325\n",
      "         10       0.29      0.26      0.28       224\n",
      "         11       0.70      0.75      0.73       495\n",
      "         12       0.75      0.78      0.76       501\n",
      "         13       0.33      0.36      0.34       209\n",
      "         14       0.69      0.66      0.68       913\n",
      "         15       0.93      0.89      0.91      1843\n",
      "         16       0.68      0.71      0.69       494\n",
      "\n",
      "avg / total       0.68      0.68      0.68      8533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classification_model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.54      0.42       319\n",
      "          1       0.38      0.38      0.38       283\n",
      "          2       0.27      0.24      0.25       220\n",
      "          3       0.72      0.73      0.73       443\n",
      "          4       0.64      0.76      0.69       406\n",
      "          5       0.52      0.27      0.35       206\n",
      "          6       0.68      0.60      0.64       805\n",
      "          7       0.64      0.65      0.65       488\n",
      "          8       0.36      0.29      0.32       359\n",
      "          9       0.51      0.37      0.43       325\n",
      "         10       0.56      0.15      0.23       224\n",
      "         11       0.67      0.65      0.66       495\n",
      "         12       0.59      0.77      0.67       501\n",
      "         13       0.27      0.39      0.32       209\n",
      "         14       0.71      0.69      0.70       913\n",
      "         15       0.89      0.89      0.89      1843\n",
      "         16       0.64      0.75      0.69       494\n",
      "\n",
      "avg / total       0.65      0.65      0.64      8533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_model_best = load_model('./model_TSC_1.hdf5')\n",
    "\n",
    "Y_pred = classification_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade of detection and classification\n",
    "The labels that have to be used for assessment are saved in Y_test_true. The labels predicted by the detection_model are saved instead in Y_pred_d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41979,) (41979,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_true.shape, Y_pred_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data from subject 1\n",
      "\n",
      "Processing data from subject 2\n",
      "\n",
      "Processing data from subject 3\n",
      "\n",
      "Processing data from subject 4\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadDataMultiple(label=label,\n",
    "                                                                                                        folder=folder,\n",
    "                                                                                                        window_size=window_size,\n",
    "                                                                                                        stride=stride,\n",
    "                                                                                                        make_binary=True,\n",
    "                                                                                                        null_class=True,\n",
    "                                                                                                        print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (Y_pred_d == 1)\n",
    "X_detected = X_test[mask, :, :]\n",
    "Y_pred_c = classification_model_best.predict_classes(X_detected)\n",
    "Y_pred_d[mask] = Y_pred_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.93     33446\n",
      "          1       0.03      0.03      0.03       319\n",
      "          2       0.11      0.07      0.09       283\n",
      "          3       0.00      0.00      0.00       220\n",
      "          4       0.01      0.01      0.01       443\n",
      "          5       0.00      0.00      0.00       406\n",
      "          6       0.01      0.05      0.02       206\n",
      "          7       0.00      0.00      0.00       805\n",
      "          8       0.00      0.00      0.00       488\n",
      "          9       0.05      0.04      0.04       359\n",
      "         10       0.03      0.01      0.01       325\n",
      "         11       0.00      0.00      0.00       224\n",
      "         12       0.01      0.01      0.01       495\n",
      "         13       0.00      0.00      0.00       501\n",
      "         14       0.00      0.01      0.00       209\n",
      "         15       0.00      0.00      0.00       913\n",
      "         16       0.09      0.02      0.04      1843\n",
      "         17       0.00      0.00      0.00       494\n",
      "\n",
      "avg / total       0.74      0.75      0.74     41979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_true, Y_pred_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-shot classification instead had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data from subject 1\n",
      "\n",
      "Processing data from subject 2\n",
      "\n",
      "Processing data from subject 3\n",
      "\n",
      "Processing data from subject 4\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadDataMultiple(label=label,\n",
    "                                                                                                        folder=folder,\n",
    "                                                                                                        window_size=window_size,\n",
    "                                                                                                        stride=stride,\n",
    "                                                                                                        make_binary=False,\n",
    "                                                                                                        null_class=True,\n",
    "                                                                                                        print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.93     33446\n",
      "          1       0.45      0.37      0.41       319\n",
      "          2       0.41      0.39      0.40       283\n",
      "          3       0.30      0.35      0.33       220\n",
      "          4       0.74      0.63      0.68       443\n",
      "          5       0.73      0.60      0.66       406\n",
      "          6       0.37      0.27      0.31       206\n",
      "          7       0.65      0.45      0.53       805\n",
      "          8       0.51      0.55      0.53       488\n",
      "          9       0.29      0.26      0.27       359\n",
      "         10       0.51      0.27      0.35       325\n",
      "         11       0.26      0.18      0.21       224\n",
      "         12       0.58      0.63      0.61       495\n",
      "         13       0.59      0.71      0.64       501\n",
      "         14       0.25      0.33      0.29       209\n",
      "         15       0.59      0.38      0.46       913\n",
      "         16       0.72      0.66      0.69      1843\n",
      "         17       0.60      0.45      0.51       494\n",
      "\n",
      "avg / total       0.85      0.85      0.85     41979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneshot_model_best = load_model('./model_OS_1.hdf5')\n",
    "\n",
    "Y_pred = oneshot_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
