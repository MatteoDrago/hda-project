{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDA - Project 3\n",
    "\n",
    "This first cell contains the parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- label_col: index of feature column to be selected to perform activity detection, between [0,6];\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "label = 6   # default for task B1\n",
    "folder = \"../data/full/\"\n",
    "window_size = 15\n",
    "stride = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "import models\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we make use of some functions of Keras which have been removed, but of which the code is still available at https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7. These are used to evaulate the f1 score during training on batches of data: this is only an approximation though, which is the reason why they have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred): \n",
    "    \"\"\"Precision metric.\n",
    "    \n",
    "    Only computes a batch-wise average of precision. \n",
    "    Computes the precision, a metric for multi-label classification of \n",
    "    how many selected items are relevant. \n",
    "    \"\"\" \n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon()) \n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred): \n",
    "    \"\"\"Recall metric. \n",
    "    \n",
    "    Only computes a batch-wise average of recall. \n",
    "    Computes the recall, a metric for multi-label classification of \n",
    "    how many relevant items are selected. \n",
    "    \"\"\" \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon()) \n",
    " \n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1): \n",
    "    \"\"\"Computes the F score. \n",
    "\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    \n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0 \n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon()) \n",
    "\n",
    "    return fbeta_score \n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    \n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\" \n",
    "\n",
    "    return fbeta_score(y_true, y_pred, beta=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with null class\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data from subject 1\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.66779111 0.01365242 0.01473443 0.01120199 0.02020813 0.02074913\n",
      " 0.01183846 0.01613468 0.01307959 0.01377972 0.01584826 0.01225217\n",
      " 0.02132196 0.02199026 0.01152022 0.01724851 0.07889126 0.01775769]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.77548892 0.00764885 0.00591047 0.00808344 0.01425467 0.01156019\n",
      " 0.00365059 0.01833985 0.00990874 0.0065189  0.00808344 0.00582355\n",
      " 0.01642764 0.01399392 0.00295524 0.01521078 0.06996958 0.00617123]\n",
      "\n",
      "Processing data from subject 2\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (38733, 110)\n",
      "ADL2:   (26824, 110)\n",
      "ADL3:   (31242, 110)\n",
      "ADL4:   (29723, 110)\n",
      "ADL5:   (27997, 110)\n",
      "Drill:  (49009, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.6284852  0.01879351 0.01416372 0.00823073 0.0201996  0.02157138\n",
      " 0.00956823 0.02249734 0.01831339 0.02222298 0.01265475 0.01063137\n",
      " 0.01978806 0.01913646 0.0143009  0.02493227 0.08103844 0.03347166]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.8403223  0.00935713 0.00658465 0.00294576 0.00441864 0.00944377\n",
      " 0.0030324  0.0183677  0.01031017 0.01221625 0.00641137 0.00407208\n",
      " 0.00537169 0.00953041 0.00441864 0.02269971 0.01602842 0.0144689 ]\n",
      "\n",
      "Processing data from subject 3\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32340, 110)\n",
      "ADL2:   (24918, 110)\n",
      "ADL3:   (24395, 110)\n",
      "ADL4:   (25169, 110)\n",
      "ADL5:   (23836, 110)\n",
      "Drill:  (68445, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.65879335 0.01522471 0.01389213 0.01096046 0.01868941 0.02045508\n",
      " 0.01069394 0.02238731 0.01552454 0.01502482 0.01339241 0.01182663\n",
      " 0.02152114 0.02395309 0.01192657 0.02571876 0.07115968 0.01885598]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.78252883 0.0081641  0.00704153 0.00326564 0.00928666 0.00908256\n",
      " 0.00704153 0.01745076 0.01387897 0.00989897 0.0085723  0.00510256\n",
      " 0.00734769 0.01193999 0.00428615 0.0290846  0.05867946 0.00734769]\n",
      "\n",
      "Processing data from subject 4\n",
      "\n",
      "Session shapes:\n",
      "ADL1:   (32076, 110)\n",
      "ADL2:   (23717, 110)\n",
      "ADL3:   (20794, 110)\n",
      "ADL4:   (18668, 110)\n",
      "ADL5:   (27007, 110)\n",
      "Drill:  (41906, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.64905469 0.01612086 0.01240716 0.01008609 0.01911715 0.01996117\n",
      " 0.00915766 0.02536293 0.01341999 0.01768231 0.01295577 0.01114112\n",
      " 0.01928596 0.01966577 0.01266036 0.02553174 0.07866307 0.0277262 ]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.78364174 0.0047082  0.00766451 0.00667908 0.01500055 0.00821198\n",
      " 0.00656958 0.02310303 0.01302967 0.00503668 0.00810249 0.00656958\n",
      " 0.0188328  0.01237271 0.00897843 0.02091317 0.03043907 0.02014672]\n",
      "\n",
      "Shapes: \n",
      "X_train:  (114295, 15, 110) \n",
      "Y_train:  (114295, 18) \n",
      "X_test:  (41979, 15, 110) \n",
      "Y_test:  (41979, 18)\n",
      "\n",
      "Class weights:\n",
      " [0.08527123 3.49654307 4.00108521 5.47389847 2.83723066 2.68147053\n",
      " 5.34038875 2.60661832 3.67248249 3.25459878 4.02901156 4.8323609\n",
      " 2.70200946 2.60876016 4.41873502 2.39974385 0.7181319  2.30312739]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadDataMultiple(label=label,\n",
    "                                                                                                        folder=folder,\n",
    "                                                                                                        window_size=window_size,\n",
    "                                                                                                        stride=stride,\n",
    "                                                                                                        make_binary=False,\n",
    "                                                                                                        null_class=True,\n",
    "                                                                                                        print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 15, 110)           440       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 5, 36)             43596     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 5, 36)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2, 36)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 2, 600)            1528800   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 600)               2882400   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               307712    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                9234      \n",
      "=================================================================\n",
      "Total params: 4,772,182\n",
      "Trainable params: 4,771,962\n",
      "Non-trainable params: 220\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "detection_model = models.MotionDetection((window_size, n_features), n_classes)\n",
    "\n",
    "detection_model.compile(optimizer = Adam(lr=0.001),\n",
    "                        loss = \"categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\", fmeasure])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./weights_1.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114295 samples, validate on 41979 samples\n",
      "Epoch 1/20\n",
      " 47056/114295 [===========>..................] - ETA: 2:10 - loss: 0.9074 - acc: 0.7332 - fmeasure: 0.7275"
     ]
    }
   ],
   "source": [
    "detection_model.fit(x = X_train, \n",
    "                    y = Y_train, \n",
    "                    epochs = 20, \n",
    "                    batch_size = 16,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[checkpointer],\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = detection_model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred, 1)\n",
    "\n",
    "print(classification_report(Y_test, to_categorical(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_best = load_model('./weights_1.hdf5')\n",
    "\n",
    "Y_pred = detection_model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred, 1)\n",
    "\n",
    "print(classification_report(Y_test, to_categorical(Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification without null class\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadData(subject=subject,\n",
    "                                                                                                label=label,\n",
    "                                                                                                folder=folder,\n",
    "                                                                                                window_size=window_size,\n",
    "                                                                                                stride=stride,\n",
    "                                                                                                make_binary=False,\n",
    "                                                                                                null_class=False,\n",
    "                                                                                                print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = models.MotionDetection((window_size, n_features), n_classes)\n",
    "\n",
    "detection_model.compile(optimizer = Adam(lr=0.001),\n",
    "                        loss = \"categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\", fmeasure])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./weights_2.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model.fit(x = X_train, \n",
    "                    y = Y_train, \n",
    "                    epochs = 20, \n",
    "                    batch_size = 16,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[checkpointer],\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = detection_model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred, 1)\n",
    "\n",
    "print(classification_report(Y_test, to_categorical(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_best = load_model('./weights_2.hdf5')\n",
    "\n",
    "Y_pred = detection_model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred, 1)\n",
    "\n",
    "print(classification_report(Y_test, to_categorical(Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity detection (binary classification)\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadData(subject=subject,\n",
    "                                                                                                label=label,\n",
    "                                                                                                folder=folder,\n",
    "                                                                                                window_size=window_size,\n",
    "                                                                                                stride=stride,\n",
    "                                                                                                make_binary=True,\n",
    "                                                                                                null_class=True,\n",
    "                                                                                                print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = models.MotionDetection((window_size, n_features), n_classes)\n",
    "\n",
    "detection_model.compile(optimizer = Adam(lr=0.001),\n",
    "                        loss = \"categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\", fmeasure])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./weights_3.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model.fit(x = X_train, \n",
    "                    y = Y_train, \n",
    "                    epochs = 20, \n",
    "                    batch_size = 16,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[checkpointer],\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = detection_model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred, 1)\n",
    "\n",
    "print(classification_report(Y_test, to_categorical(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_best = load_model('./weights_3.hdf5')\n",
    "\n",
    "Y_pred = detection_model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred, 1)\n",
    "\n",
    "print(classification_report(Y_test, to_categorical(Y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
