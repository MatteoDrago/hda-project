{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B - single subject - model ?\n",
    "\n",
    "## Notebook setup\n",
    "This first cell contains the parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- label: index of feature column to be selected to perform activity detection, between [0,6]. The default value for task B is 6;\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "label = 6\n",
    "folder = \"../data/full/\"\n",
    "window_size = 15\n",
    "stride = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "import models\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we make use of some functions of Keras which have been removed, but of which the code is still available at https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7. These are used to evaulate the f1 score during training on batches of data: this is only an approximation though, which is the reason why they have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not(os.path.exists(\"./data\")):\n",
    "    os.mkdir(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot classification\n",
    "Here classification is performed with null class.\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.66779111 0.01365242 0.01473443 0.01120199 0.02020813 0.02074913\n",
      " 0.01183846 0.01613468 0.01307959 0.01377972 0.01584826 0.01225217\n",
      " 0.02132196 0.02199026 0.01152022 0.01724851 0.07889126 0.01775769]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 18 \n",
      "Fraction of labels:   [0.77548892 0.00764885 0.00591047 0.00808344 0.01425467 0.01156019\n",
      " 0.00365059 0.01833985 0.00990874 0.0065189  0.00808344 0.00582355\n",
      " 0.01642764 0.01399392 0.00295524 0.01521078 0.06996958 0.00617123]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadData(subject=subject,\n",
    "                                                                                                label=label,\n",
    "                                                                                                folder=folder,\n",
    "                                                                                                window_size=window_size,\n",
    "                                                                                                stride=stride,\n",
    "                                                                                                make_binary=False,\n",
    "                                                                                                null_class=True,\n",
    "                                                                                                print_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train and Y_test contain the correct labels for each signals window. Y_test in particular will be used to evaluate predictions for both this (one-shot) and the two-steps models. For this reason it is here saved with a different name, to avoid having it being overwritten later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_true = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_model = models.MotionDetection((window_size, n_features), n_classes, print_info=False)\n",
    "\n",
    "oneshot_model.compile(optimizer = Adam(lr=0.001),\n",
    "                      loss = \"categorical_crossentropy\", \n",
    "                      metrics = [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model_OS_1.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31423, 15, 110)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31423 samples, validate on 11505 samples\n",
      "Epoch 1/15\n",
      "31423/31423 [==============================] - 68s 2ms/step - loss: 0.5801 - acc: 0.8155 - val_loss: 0.4903 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49034, saving model to ./model_OS_1.hdf5\n",
      "Epoch 2/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.3710 - acc: 0.8719 - val_loss: 0.3853 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49034 to 0.38534, saving model to ./model_OS_1.hdf5\n",
      "Epoch 3/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.2991 - acc: 0.8954 - val_loss: 0.4196 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.2522 - acc: 0.9135 - val_loss: 0.4076 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.2137 - acc: 0.9253 - val_loss: 0.4552 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1964 - acc: 0.9323 - val_loss: 0.4909 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1730 - acc: 0.9405 - val_loss: 0.4598 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1612 - acc: 0.9435 - val_loss: 0.5510 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1561 - acc: 0.9450 - val_loss: 0.4124 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1458 - acc: 0.9487 - val_loss: 0.4331 - val_acc: 0.8967\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1392 - acc: 0.9506 - val_loss: 0.4193 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1324 - acc: 0.9545 - val_loss: 0.4772 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.1312 - acc: 0.9551 - val_loss: 0.5563 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1269 - acc: 0.9557 - val_loss: 0.5108 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.1237 - acc: 0.9573 - val_loss: 0.4873 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e60058c978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneshot_model.fit(x = X_train, \n",
    "                  y = to_categorical(Y_train),\n",
    "                  epochs = 15,\n",
    "                  batch_size = 16,\n",
    "                  verbose = 1,\n",
    "                  callbacks=[checkpointer],\n",
    "                  validation_data=(X_test, to_categorical(Y_test)),\n",
    "                  class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - passare class_weights a class report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95      8922\n",
      "          1       0.48      0.25      0.33        88\n",
      "          2       0.56      0.15      0.23        68\n",
      "          3       0.57      0.13      0.21        93\n",
      "          4       0.82      0.73      0.77       164\n",
      "          5       0.79      0.80      0.80       133\n",
      "          6       0.32      0.90      0.48        42\n",
      "          7       0.83      0.43      0.56       211\n",
      "          8       0.95      0.65      0.77       114\n",
      "          9       0.95      0.25      0.40        75\n",
      "         10       0.65      0.62      0.64        93\n",
      "         11       0.29      0.28      0.29        67\n",
      "         12       0.89      0.69      0.78       189\n",
      "         13       0.82      0.80      0.81       161\n",
      "         14       0.00      0.00      0.00        34\n",
      "         15       0.60      0.77      0.68       175\n",
      "         16       0.85      0.88      0.86       805\n",
      "         17       1.00      0.11      0.20        71\n",
      "\n",
      "avg / total       0.89      0.90      0.89     11505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = oneshot_model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94      8922\n",
      "          1       0.44      0.17      0.25        88\n",
      "          2       0.37      0.68      0.47        68\n",
      "          3       0.33      0.26      0.29        93\n",
      "          4       0.68      0.82      0.74       164\n",
      "          5       0.75      0.63      0.69       133\n",
      "          6       0.43      0.14      0.21        42\n",
      "          7       0.84      0.36      0.50       211\n",
      "          8       0.93      0.61      0.73       114\n",
      "          9       0.38      0.13      0.20        75\n",
      "         10       0.38      0.46      0.42        93\n",
      "         11       0.32      0.13      0.19        67\n",
      "         12       0.84      0.62      0.71       189\n",
      "         13       0.74      0.81      0.77       161\n",
      "         14       0.55      0.18      0.27        34\n",
      "         15       0.53      0.79      0.64       175\n",
      "         16       0.90      0.66      0.76       805\n",
      "         17       0.68      0.82      0.74        71\n",
      "\n",
      "avg / total       0.88      0.88      0.87     11505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneshot_model_best = load_model('./model_OS_1.hdf5')\n",
    "\n",
    "Y_pred = oneshot_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-steps classification\n",
    "## Activity detection\n",
    "This model performs a binary classification.\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.66718646 0.33281354]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 2 \n",
      "Fraction of labels:   [0.775402 0.224598]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadData(subject=subject,\n",
    "                                                                                                label=label,\n",
    "                                                                                                folder=folder,\n",
    "                                                                                                window_size=window_size,\n",
    "                                                                                                stride=stride,\n",
    "                                                                                                make_binary=True,\n",
    "                                                                                                null_class=True,\n",
    "                                                                                                print_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = models.MotionDetection((window_size, n_features), n_classes, print_info=False)\n",
    "\n",
    "detection_model.compile(optimizer = Adam(lr=0.001),\n",
    "                        loss = \"categorical_crossentropy\", \n",
    "                        metrics = [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model_TSD_1.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31423 samples, validate on 11505 samples\n",
      "Epoch 1/15\n",
      "31423/31423 [==============================] - 64s 2ms/step - loss: 0.2578 - acc: 0.8956 - val_loss: 0.2611 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26107, saving model to ./model_TSD_1.hdf5\n",
      "Epoch 2/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.1789 - acc: 0.9296 - val_loss: 0.2546 - val_acc: 0.8984\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26107 to 0.25456, saving model to ./model_TSD_1.hdf5\n",
      "Epoch 3/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.1493 - acc: 0.9398 - val_loss: 0.2510 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25456 to 0.25104, saving model to ./model_TSD_1.hdf5\n",
      "Epoch 4/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.1323 - acc: 0.9474 - val_loss: 0.2828 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.1199 - acc: 0.9517 - val_loss: 0.2849 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.1125 - acc: 0.9561 - val_loss: 0.2611 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.1046 - acc: 0.9580 - val_loss: 0.3254 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.0972 - acc: 0.9607 - val_loss: 0.2661 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.0925 - acc: 0.9633 - val_loss: 0.2776 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.0926 - acc: 0.9642 - val_loss: 0.3266 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.0840 - acc: 0.9672 - val_loss: 0.3096 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/15\n",
      "31423/31423 [==============================] - 60s 2ms/step - loss: 0.0829 - acc: 0.9671 - val_loss: 0.3538 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.0815 - acc: 0.9683 - val_loss: 0.2931 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.0745 - acc: 0.9706 - val_loss: 0.3106 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/15\n",
      "31423/31423 [==============================] - 61s 2ms/step - loss: 0.0751 - acc: 0.9702 - val_loss: 0.4075 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e60053ee48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.fit(x = X_train, \n",
    "                    y = to_categorical(Y_train), \n",
    "                    epochs = 15, \n",
    "                    batch_size = 16,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[checkpointer],\n",
    "                    validation_data=(X_test, to_categorical(Y_test)),\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93      8921\n",
      "          1       0.84      0.66      0.74      2584\n",
      "\n",
      "avg / total       0.89      0.90      0.89     11505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = detection_model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95      8921\n",
      "          1       0.83      0.81      0.82      2584\n",
      "\n",
      "avg / total       0.92      0.92      0.92     11505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detection_model_best = load_model('./model_TSD_1.hdf5')\n",
    "\n",
    "Y_pred = detection_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_d = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.04109589 0.04435291 0.0337197  0.06082958 0.06245809 0.0356356\n",
      " 0.04856787 0.03937159 0.04147907 0.04770572 0.03688093 0.06418239\n",
      " 0.06619408 0.03467765 0.05192068 0.23747485 0.0534534 ]\n",
      "\n",
      "Features: 110 \n",
      "Classes: 17 \n",
      "Fraction of labels:   [0.03406891 0.02632598 0.03600465 0.06349206 0.05149051 0.01626016\n",
      " 0.08168796 0.04413473 0.029036   0.03600465 0.02593883 0.07317073\n",
      " 0.06233062 0.01316299 0.06775068 0.31165312 0.02748742]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadData(subject=subject,\n",
    "                                                                                                label=label,\n",
    "                                                                                                folder=folder,\n",
    "                                                                                                window_size=window_size,\n",
    "                                                                                                stride=stride,\n",
    "                                                                                                make_binary=False,\n",
    "                                                                                                null_class=False,\n",
    "                                                                                                print_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = models.MotionDetection((window_size, n_features), n_classes, print_info=False)\n",
    "\n",
    "classification_model.compile(optimizer = Adam(lr=0.001),\n",
    "                             loss = \"categorical_crossentropy\", \n",
    "                             metrics = [\"accuracy\"])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model_TSC_1.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10439 samples, validate on 2583 samples\n",
      "Epoch 1/15\n",
      "10439/10439 [==============================] - 24s 2ms/step - loss: 0.8864 - acc: 0.6645 - val_loss: 0.9145 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.91446, saving model to ./model_TSC_1.hdf5\n",
      "Epoch 2/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.5450 - acc: 0.7882 - val_loss: 0.8309 - val_acc: 0.7398\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.91446 to 0.83090, saving model to ./model_TSC_1.hdf5\n",
      "Epoch 3/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.3889 - acc: 0.8570 - val_loss: 1.0135 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.3168 - acc: 0.8873 - val_loss: 0.9528 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.2588 - acc: 0.9114 - val_loss: 0.9028 - val_acc: 0.7615\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.2273 - acc: 0.9211 - val_loss: 0.8611 - val_acc: 0.7569\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1905 - acc: 0.9340 - val_loss: 0.7829 - val_acc: 0.7902\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.83090 to 0.78287, saving model to ./model_TSC_1.hdf5\n",
      "Epoch 8/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1664 - acc: 0.9443 - val_loss: 0.9055 - val_acc: 0.7863\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1475 - acc: 0.9520 - val_loss: 1.0425 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1502 - acc: 0.9498 - val_loss: 1.0051 - val_acc: 0.7766\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1307 - acc: 0.9600 - val_loss: 0.9859 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1253 - acc: 0.9587 - val_loss: 0.9814 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1127 - acc: 0.9647 - val_loss: 1.0785 - val_acc: 0.7669\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1166 - acc: 0.9644 - val_loss: 0.9106 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/15\n",
      "10439/10439 [==============================] - 20s 2ms/step - loss: 0.1107 - acc: 0.9653 - val_loss: 1.0059 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e620e7eb38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(x = X_train,\n",
    "                         y = to_categorical(Y_train), \n",
    "                         epochs = 15, \n",
    "                         batch_size = 16,\n",
    "                         verbose = 1,\n",
    "                         callbacks=[checkpointer],\n",
    "                         validation_data=(X_test, to_categorical(Y_test)),\n",
    "                         class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.24      0.30        88\n",
      "          1       0.66      0.71      0.68        68\n",
      "          2       0.55      0.25      0.34        93\n",
      "          3       0.73      0.77      0.75       164\n",
      "          4       0.76      0.86      0.81       133\n",
      "          5       0.54      0.93      0.68        42\n",
      "          6       0.77      0.62      0.69       211\n",
      "          7       0.84      0.77      0.80       114\n",
      "          8       0.44      0.36      0.40        75\n",
      "          9       0.53      0.89      0.66        93\n",
      "         10       0.29      0.15      0.20        67\n",
      "         11       0.73      0.65      0.69       189\n",
      "         12       0.82      0.83      0.82       161\n",
      "         13       0.18      0.26      0.21        34\n",
      "         14       0.68      0.83      0.75       175\n",
      "         15       0.97      1.00      0.99       805\n",
      "         16       0.99      0.93      0.96        71\n",
      "\n",
      "avg / total       0.77      0.77      0.76      2583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classification_model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.39      0.44        88\n",
      "          1       0.73      0.65      0.69        68\n",
      "          2       0.62      0.45      0.52        93\n",
      "          3       0.71      0.85      0.77       164\n",
      "          4       0.77      0.68      0.72       133\n",
      "          5       0.55      0.86      0.67        42\n",
      "          6       0.84      0.64      0.73       211\n",
      "          7       0.86      0.84      0.85       114\n",
      "          8       0.60      0.37      0.46        75\n",
      "          9       0.56      0.74      0.64        93\n",
      "         10       0.35      0.28      0.31        67\n",
      "         11       0.83      0.66      0.73       189\n",
      "         12       0.71      0.88      0.79       161\n",
      "         13       0.50      0.29      0.37        34\n",
      "         14       0.66      0.90      0.76       175\n",
      "         15       0.97      1.00      0.99       805\n",
      "         16       0.92      0.97      0.95        71\n",
      "\n",
      "avg / total       0.79      0.79      0.78      2583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_model_best = load_model('./model_TSC_1.hdf5')\n",
    "\n",
    "Y_pred = classification_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade of detection and classification\n",
    "The labels that have to be used for assessment are saved in Y_test_true. The labels predicted by the detection_model are saved instead in Y_pred_d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11505,) (11505,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_true.shape, Y_pred_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadData(subject=subject,\n",
    "                                                                                                label=label,\n",
    "                                                                                                folder=folder,\n",
    "                                                                                                window_size=window_size,\n",
    "                                                                                                stride=stride,\n",
    "                                                                                                make_binary=True,\n",
    "                                                                                                null_class=True,\n",
    "                                                                                                print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (Y_pred_d == 1)\n",
    "X_detected = X_test[mask, :, :]\n",
    "Y_pred_c = classification_model_best.predict_classes(X_detected)\n",
    "Y_pred_d[mask] = Y_pred_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95      8922\n",
      "          1       0.00      0.00      0.00        88\n",
      "          2       0.00      0.00      0.00        68\n",
      "          3       0.01      0.01      0.01        93\n",
      "          4       0.02      0.01      0.01       164\n",
      "          5       0.00      0.00      0.00       133\n",
      "          6       0.00      0.00      0.00        42\n",
      "          7       0.01      0.00      0.01       211\n",
      "          8       0.00      0.00      0.00       114\n",
      "          9       0.02      0.04      0.03        75\n",
      "         10       0.08      0.05      0.06        93\n",
      "         11       0.00      0.00      0.00        67\n",
      "         12       0.00      0.00      0.00       189\n",
      "         13       0.00      0.00      0.00       161\n",
      "         14       0.02      0.12      0.03        34\n",
      "         15       0.00      0.00      0.00       175\n",
      "         16       0.00      0.00      0.00       805\n",
      "         17       0.00      0.00      0.00        71\n",
      "\n",
      "avg / total       0.73      0.74      0.74     11505\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_true, Y_pred_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-shot classification instead had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_features, n_classes, class_weights = preprocessing.loadData(subject=subject,\n",
    "                                                                                                label=label,\n",
    "                                                                                                folder=folder,\n",
    "                                                                                                window_size=window_size,\n",
    "                                                                                                stride=stride,\n",
    "                                                                                                make_binary=False,\n",
    "                                                                                                null_class=True,\n",
    "                                                                                                print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94      8922\n",
      "          1       0.44      0.17      0.25        88\n",
      "          2       0.37      0.68      0.47        68\n",
      "          3       0.33      0.26      0.29        93\n",
      "          4       0.68      0.82      0.74       164\n",
      "          5       0.75      0.63      0.69       133\n",
      "          6       0.43      0.14      0.21        42\n",
      "          7       0.84      0.36      0.50       211\n",
      "          8       0.93      0.61      0.73       114\n",
      "          9       0.38      0.13      0.20        75\n",
      "         10       0.38      0.46      0.42        93\n",
      "         11       0.32      0.13      0.19        67\n",
      "         12       0.84      0.62      0.71       189\n",
      "         13       0.74      0.81      0.77       161\n",
      "         14       0.55      0.18      0.27        34\n",
      "         15       0.53      0.79      0.64       175\n",
      "         16       0.90      0.66      0.76       805\n",
      "         17       0.68      0.82      0.74        71\n",
      "\n",
      "avg / total       0.88      0.88      0.87     11505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneshot_model_best = load_model('./model_OS_1.hdf5')\n",
    "\n",
    "Y_pred = oneshot_model_best.predict_classes(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
