{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDA - Project 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import deeplearning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.activations import relu\n",
    "from keras.layers import Conv2D, BatchNormalization, Dropout, LeakyReLU, Flatten, Activation, Dense, MaxPooling2D, LSTM, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the hyper-parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- label_col: column of features to be selected to perform activity detection, between [0,6]:\n",
    "\n",
    "|  Label |  Feature |\n",
    "|:-:     |:-:|\n",
    "|  0     | Locomotion (TASK A)  |\n",
    "|  1     | High Level Activity |\n",
    "|  2     | Low Level Left Arm  |\n",
    "|  3     | Low Level Left Arm Object  |\n",
    "|  4     | Low Level Right Arm  |\n",
    "|  5     | Low Level Right Arm Object  |\n",
    "|  6     | Medium Level Both Arms (TASK B2) |\n",
    "\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window.\n",
    "\n",
    "The size of the temporal window seems to be fundamental in order to get a more specific and powerful model; of course the choice of the step lenght between consequent windows has to be consistent and to make sense. Thinking about a real-time situation, as long as we collect data we can use a sliding window of real-time samples; in this way, it is reasonable to use also a small value for the stride. Another important reason behind the choice of the value of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "folder = \"./data/reduced/\"\n",
    "#folder = \"/floyd/input/hdadataset/full/\" # To be used with FloydHub\n",
    "label = 0     # default for task A\n",
    "window_size = 64\n",
    "stride = 3\n",
    "null_class = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 58)\n",
      "ADL2:   (28996, 58)\n",
      "ADL3:   (30167, 58)\n",
      "ADL4:   (30228, 58)\n",
      "ADL5:   (27308, 58)\n",
      "Drill:  (52152, 58)\n",
      "Training samples:  157125 \n",
      "Test samples:       57536 \n",
      "Features:             58\n",
      "TRAINING SET:\n",
      "Features have shape:  (52354, 64, 58) \n",
      "Labels have shape:    (52354, 5) \n",
      "Fraction of labels:   [0.10988654 0.41987241 0.27476411 0.17119991 0.02427704]\n",
      "TEST SET:\n",
      "Features have shape:  (19157, 64, 58) \n",
      "Labels have shape:    (19157, 5) \n",
      "Fraction of labels:   [0.17742862 0.34337318 0.20290233 0.23771989 0.03857598]\n"
     ]
    }
   ],
   "source": [
    "[x_train, y_train, x_test, y_test, n_classes] = utils.preprocessing(subject,\n",
    "                                                         folder,\n",
    "                                                         label,\n",
    "                                                         window_size,\n",
    "                                                         stride,\n",
    "                                                         null_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Neural Network\n",
    "In the following section we have implemented the neural network proposed in [1], with one block consisting of (Batch Normalization + Conv2D + MaxPool2D) followed by two layers of **LSTM**. \n",
    "\n",
    "Particular emphasis should be given to how we pass the output of the convolutional block to the recurrent layers; in fact, we need to appropriately reshape the output in order to make it consistent. As we know, the _convolutional power_  consists on being able to extract significant features from our input data; with the reshape procedure we merge these features in order to give them a sense of temporal dependency.\n",
    "\n",
    "Practical example using the following problem: in our case, our samples consist of 64x110 images and we implemented 50 distinct filters in the convolutional block. So, after the conv block, our images are represented by a 27x110x50 tensor. In order to shift this in the _temporal domain_ we consider the 27 lines as temporal dependant and we represent each line as a feature vector of size 110x50. After this procedure we can feed the recurrent neural network appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HybridFeatsCorr(input_shape, classes, withSoftmax = True):\n",
    "    \n",
    "    model = Sequential()\n",
    "  \n",
    "    # Layer 0\n",
    "    model.add(BatchNormalization(input_shape = input_shape))\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(filters = 50,\n",
    "                    kernel_size = (11,3),\n",
    "                    strides=(1,1),\n",
    "                    activation='relu'))\n",
    "    \n",
    "    # Layer 2\n",
    "    model.add(MaxPooling2D(pool_size=(2,1)))\n",
    "    \n",
    "    # Layer 3\n",
    "    # This layer dimension are automatically scanned in order to avoid updating by hand each time\n",
    "    model.add(Reshape((model.layers[2].output_shape[1],model.layers[2].output_shape[2] * model.layers[2].output_shape[3])))  \n",
    "\n",
    "    # Layer 4\n",
    "    model.add(LSTM(300,\n",
    "                  return_sequences=True))\n",
    "    \n",
    "    # Layer 5 \n",
    "    model.add(LSTM(300))\n",
    "   \n",
    "    # Layer 6\n",
    "    model.add(Dense(512,activation = 'relu'))\n",
    "    \n",
    "    if (withSoftmax):\n",
    "        # Layer 7\n",
    "        model.add(Dense(classes, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 64, 58, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 54, 56, 50)        1700      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 27, 56, 50)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 27, 2800)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 27, 300)           3721200   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 4,600,781\n",
      "Trainable params: 4,600,779\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_features = x_train.shape[2] #number of features taken into consideration for the solution of the problem\n",
    "\n",
    "model_hyb = HybridFeatsCorr((window_size,n_features,1), n_classes)\n",
    "model_hyb.summary() # model visualization\n",
    "\n",
    "model_hyb.compile(optimizer = Adam(lr=0.01), \n",
    "                   loss = \"categorical_crossentropy\", \n",
    "                   metrics = [\"accuracy\"])\n",
    "\n",
    "input_train = x_train.reshape(x_train.shape[0], window_size, n_features, 1)\n",
    "input_test = x_test.reshape(x_test.shape[0], window_size, n_features, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just an implementation note: if we want to use the 2D convolution, we have to add to our input the _depth_ information. Only out dataset representation changes, not its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyb.fit(x = input_train, \n",
    "               y = y_train, \n",
    "               epochs = 25, \n",
    "               batch_size = 300,\n",
    "               verbose = 1,\n",
    "               validation_data=(input_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DNN features on the training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: 100%|#####################################################| 88/88 [06:30<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DNN features on the testing set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TESTING: 100%|######################################################| 32/32 [02:08<00:00,  4.02s/it]\n"
     ]
    }
   ],
   "source": [
    "[trainingFeatures, testingFeatures] = deeplearning.extractFeatures(model,\n",
    "                                                                   input_train,\n",
    "                                                                   input_test,\n",
    "                                                                   model_hyb.layers[-1].output_shape[1],\n",
    "                                                                   batchSize = 300)\n",
    "\n",
    "np.save('./features_training.npy',trainingFeatures)\n",
    "np.save('./labels_training.npy',y_train)\n",
    "np.save('./features_testing.npy',testingFeatures)\n",
    "np.save('./labels_testing.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reverse the one-hot encoder procedure in order to obtain the output labels\n",
    "output_train = np.argmax(y_train, axis=1)\n",
    "output_test = np.argmax(y_test, axis=1)\n",
    "prediction_encoded = model.predict(input_test)\n",
    "prediction = np.argmax(prediction_encoded, axis=1)\n",
    "\n",
    "C = [2**(-6)]\n",
    "prediction_svm = deeplearning.SVMLayer(C,\n",
    "                                        output_train,\n",
    "                                        trainingFeatures,\n",
    "                                        testingFeatures) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBEFORE SVM:\")\n",
    "print(\"Accuracy: \", accuracy_score(output_test, prediction))\n",
    "print(\"F1-measure: \", utils.f1_score(output_test, prediction, average='weighted'))\n",
    "\n",
    "print(\"\\nAFTER SVM:\")\n",
    "print(\"Accuracy: \", accuracy_score(output_test, prediction_svm))\n",
    "print(\"F1-measure: \", utils.f1_score(output_test, prediction_svm, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
