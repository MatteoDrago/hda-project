{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDA - Project 3: TASK A\n",
    "## Activity detection\n",
    "This first cell contains the parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- label_col: column of features to be selected to perform activity detection, between [0,6];\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 2\n",
    "folder = \"./data/reduced_nozero/\"\n",
    "trim_zeros = True\n",
    "label_col = 0     # default for task A\n",
    "window_size = 15\n",
    "stride = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session shapes:\n",
      "ADL1:   (34928, 55)\n",
      "ADL2:   (23108, 55)\n",
      "ADL3:   (26659, 55)\n",
      "ADL4:   (25517, 55)\n",
      "ADL5:   (22969, 55)\n",
      "Drill:  (47264, 55)\n",
      "\n",
      "Training samples:  131959 \n",
      "Test samples:       48486 \n",
      "Features:             55\n"
     ]
    }
   ],
   "source": [
    "# import all sessions for a subject\n",
    "(data1, data2, data3, data4, data5, data6) = utils.loadData(subject, folder=folder)\n",
    "\n",
    "# create training set and test set\n",
    "X_train = np.concatenate((data1['features'],\\\n",
    "                          data2['features'],\\\n",
    "                          data3['features'],\\\n",
    "                          data6['features']), axis=0)\n",
    "\n",
    "Y_train = np.concatenate((data1['labels'][:,label_col],\\\n",
    "                          data2['labels'][:,label_col],\\\n",
    "                          data3['labels'][:,label_col],\\\n",
    "                          data6['labels'][:,label_col]), axis=0)\n",
    "\n",
    "X_test = np.concatenate((data4['features'],\\\n",
    "                         data5['features']), axis=0)\n",
    "\n",
    "Y_test = np.concatenate((data4['labels'][:,label_col],\\\n",
    "                         data5['labels'][:,label_col]))\n",
    "\n",
    "features = X_test.shape[1]\n",
    "\n",
    "if trim_zeros:\n",
    "    mask = np.where(Y_train == 0)[0]\n",
    "    Y_train = np.delete(Y_train,mask)\n",
    "    X_train = np.delete(X_train,mask,axis=0)\n",
    "\n",
    "    mask = np.where(Y_test == 0)[0]\n",
    "    Y_test = np.delete(Y_test,mask)\n",
    "    X_test = np.delete(X_test,mask,axis=0)\n",
    "\n",
    "print(\"\\nTraining samples: \", X_train.shape[0],\\\n",
    "      \"\\nTest samples:      \", X_test.shape[0],\\\n",
    "      \"\\nFeatures:            \", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes in training set:  4 \n",
      "Classes in test set:      4\n"
     ]
    }
   ],
   "source": [
    "# decision to overcome the problem of entire missing columns\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "# features normalization\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train =scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# make the problem binary\n",
    "#Y_train[Y_train != 0] = 1\n",
    "#Y_test[Y_test != 0] = 1\n",
    "\n",
    "# switch to one hot encoded labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False,categorical_features='all')\n",
    "\n",
    "Y_train_oh = onehot_encoder.fit_transform(Y_train.reshape(-1, 1))\n",
    "Y_test_oh = onehot_encoder.fit_transform(Y_test.reshape(-1, 1))\n",
    "print(\"\\nClasses in training set: \", Y_train_oh.shape[1],\\\n",
    "      \"\\nClasses in test set:     \", Y_test_oh.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of data in a input-suitable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onehot_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3ddea77c2cf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepareData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_oh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY_train_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_temp_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepareData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_oh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mY_test_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_temp_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Università degli Studi di Padova\\Università\\Magistrale\\Human Data Analytics\\hda-project\\code\\utils.py\u001b[0m in \u001b[0;36mprepareData\u001b[1;34m(X, Y, window_size, stride, shuffle)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m#Y_out[i, np.argmax(np.sum(temp, axis=0))] = 1 # hard version      CHECK!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[1;31m#Y_out = onehot_encoder.fit_transform(lab_cum.reshape(-1, 1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     print(\"\\nFeatures have shape: \", X_out.shape,\\\n\u001b[0;32m     65\u001b[0m           \u001b[1;34m\"\\nLabels have shape:   \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'onehot_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_s, Y_temp = utils.prepareData(X_train, Y_train_oh, window_size, stride, shuffle=False)\n",
    "Y_train_s = onehot_encoder.fit_transform(Y_temp.reshape(-1, 1))\n",
    "X_test_s, Y_temp_s = utils.prepareData(X_test, Y_test_oh, window_size, stride, shuffle=False)\n",
    "Y_test_s = onehot_encoder.fit_transform(Y_temp_s.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.max((Y_train_oh.shape[1], Y_test_oh.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Performances\n",
    "\n",
    "## 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unidim = utils.Model1D((window_size, features), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01)\n",
    "model_unidim.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model_unidim.fit(x = X_train_s, y = Y_train_s, epochs = 5, batch_size = 128, validation_data=(X_test_s, Y_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels\n",
    "Y_pred_s = model_unidim.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "#reverse the one-hot encoder procedure\n",
    "Y_test_hard = np.argmax(Y_test_s, axis=1)\n",
    "Y_pred_hard = np.argmax(Y_pred_s, axis=1)\n",
    "\n",
    "print(\"F1-measure: \", utils.f1_score(Y_test_hard, Y_pred_hard, average='weighted'))\n",
    "print(\"AUC w.r. to each class: \", utils.AUC(Y_test_s, Y_pred_s, classes))\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cnf_matrix = utils.confusion_matrix(Y_test_hard, Y_pred_hard)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_confusion_matrix(cnf_matrix,classes = [1,2,4,5],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
