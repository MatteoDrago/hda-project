{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDA - Project 3: TASK A\n",
    "## Classification of Modes of Locomotion\n",
    "This first cell contains the parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- label_col: column of features to be selected to perform activity detection, between [0,6];\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv1D, Conv2D, BatchNormalization, Dropout, LeakyReLU, Flatten, Activation, Dense, MaxPooling1D, MaxPooling2D, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters definition\n",
    "\n",
    "subject = 1\n",
    "folder = \"./data/full/\"\n",
    "label_col = 0     # default for task A\n",
    "window_size = 50\n",
    "stride = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 - Loading and Preprocessing\n",
    "\n",
    "### Dataset Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session shapes:\n",
      "ADL1:   (45810, 110)\n",
      "ADL2:   (28996, 110)\n",
      "ADL3:   (30167, 110)\n",
      "ADL4:   (30228, 110)\n",
      "ADL5:   (27308, 110)\n",
      "Drill:  (52152, 110)\n",
      "\n",
      "Training samples:  157125 \n",
      "Test samples:       57536 \n",
      "Features:             110\n"
     ]
    }
   ],
   "source": [
    "# import all sessions for a subject\n",
    "(data1, data2, data3, data4, data5, data6) = utils.loadData(subject, folder=folder)\n",
    "\n",
    "# create training set and test set\n",
    "X_train = np.concatenate((data1['features_interp'],\\\n",
    "                          data2['features_interp'],\\\n",
    "                          data3['features_interp'],\\\n",
    "                          data6['features_interp']), axis=0)\n",
    "\n",
    "Y_train = np.concatenate((data1['labels_cut'][:,label_col],\\\n",
    "                          data2['labels_cut'][:,label_col],\\\n",
    "                          data3['labels_cut'][:,label_col],\\\n",
    "                          data6['labels_cut'][:,label_col]), axis=0)\n",
    "\n",
    "X_test = np.concatenate((data4['features_interp'],\\\n",
    "                         data5['features_interp']), axis=0)\n",
    "\n",
    "Y_test = np.concatenate((data4['labels_cut'][:,label_col],\\\n",
    "                         data5['labels_cut'][:,label_col]))\n",
    "\n",
    "features = X_test.shape[1]\n",
    "print(\"\\nTraining samples: \", X_train.shape[0],\\\n",
    "      \"\\nTest samples:      \", X_test.shape[0],\\\n",
    "      \"\\nFeatures:            \", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation in order to feed it to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes in training set:  5 \n",
      "Classes in test set:      5\n",
      "Training set:\n",
      "<class 'numpy.ndarray'> (3141, 50, 110) <class 'numpy.ndarray'> (3141, 5)\n",
      "\n",
      "Features have shape:  (3141, 50, 110) \n",
      "Labels have shape:    (3141, 5) \n",
      "Fraction of labels:   [0.10983763 0.4237504  0.27029608 0.17191977 0.02419612]\n",
      "\n",
      "Test set:\n",
      "<class 'numpy.ndarray'> (1149, 50, 110) <class 'numpy.ndarray'> (1149, 5)\n",
      "\n",
      "Features have shape:  (1149, 50, 110) \n",
      "Labels have shape:    (1149, 5) \n",
      "Fraction of labels:   [0.17928634 0.34290688 0.20104439 0.23846823 0.03829417]\n"
     ]
    }
   ],
   "source": [
    "# decision to overcome the problem of entire missing columns\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "# features normalization\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train =scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# switch to one hot encoded labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "Y_train_oh = onehot_encoder.fit_transform(Y_train.reshape(-1, 1))\n",
    "Y_test_oh = onehot_encoder.fit_transform(Y_test.reshape(-1, 1))\n",
    "print(\"\\nClasses in training set: \", Y_train_oh.shape[1],\\\n",
    "      \"\\nClasses in test set:     \", Y_test_oh.shape[1])\n",
    "\n",
    "print(\"Training set:\")\n",
    "X_train_s, Y_train_s = utils.prepareData(X_train, Y_train_oh, window_size, stride, shuffle=False)\n",
    "print(\"\\nTest set:\")\n",
    "X_test_s, Y_test_s = utils.prepareData(X_test, Y_test_oh, window_size, stride, shuffle=False)\n",
    "# add bars plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Classification with Conv1D\n",
    "\n",
    "### Creation of one-dimensional convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.max((Y_train_s.shape[1], Y_test_s.shape[1]))\n",
    "\n",
    "model_unidim = utils.Model1D((window_size, features), classes)\n",
    "\n",
    "opt = Adam(lr=0.01)\n",
    "model_unidim.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model_unidim.fit(x = X_train_s, y = Y_train_s, epochs = 10, batch_size = 128, validation_data=(X_test_s, Y_test_s))\n",
    "\n",
    "# Classification and evaluation of performances\n",
    "\n",
    "# predict labels\n",
    "Y_pred_s = model_unidim.predict(X_test_s)\n",
    "\n",
    "# print results\n",
    "#reverse the one-ot encoder procedure\n",
    "Y_test_hard = np.argmax(Y_test_s, axis=1)\n",
    "Y_pred_hard = np.argmax(Y_pred_s, axis=1)\n",
    "\n",
    "print(\"F1-measure: \", utils.f1_score(Y_test_hard, Y_pred_hard, average='weighted'))\n",
    "print(\"AUC w.r. to each class: \", utils.AUC(Y_test_s, Y_pred_s, classes))\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cnf_matrix = utils.confusion_matrix(Y_test_hard, Y_pred_hard)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_confusion_matrix(cnf_matrix, classes=[0,1,2,4,5],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Classification with Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1, 17, 18)         26118     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 17, 18)         72        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1, 17, 18)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 9, 18)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 3, 36)          16236     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 3, 36)          144       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 1, 3, 36)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 2, 36)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 2, 36)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 72)          64872     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 1, 72)          288       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 1, 1, 72)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 72)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4672      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 112,727\n",
      "Trainable params: 112,475\n",
      "Non-trainable params: 252\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new2D = utils.Model2D((1,window_size,features), classes)\n",
    "opt4 = Adam(lr=0.01)\n",
    "model_new2D.compile(optimizer = opt4, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "# need to reshape in order to fit to the new 2D model\n",
    "X_train = X_train_s.reshape(X_train_s.shape[0], 1, window_size, features)\n",
    "X_test = X_test_s.reshape(X_test_s.shape[0], 1, window_size, features)\n",
    "\n",
    "model_new2D.fit(x = X_train, y = Y_train_s, epochs = 10, batch_size = 128, validation_data=(X_test, Y_test_s))\n",
    "\n",
    "### Classification and evaluation of performances\n",
    "\n",
    "# predict labels\n",
    "Y_pred_s = model_new2D.predict(X_test)\n",
    "\n",
    "# print results\n",
    "#reverse the one-ot encoder procedure\n",
    "Y_test_hard = np.argmax(Y_test_s, axis=1)\n",
    "Y_pred_hard = np.argmax(Y_pred_s, axis=1)\n",
    "\n",
    "print(\"F1-measure: \", utils.f1_score(Y_test_hard, Y_pred_hard, average='weighted'))\n",
    "print(\"AUC w.r. to each class: \", utils.AUC(Y_test_s, Y_pred_s, classes))\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cnf_matrix = utils.confusion_matrix(Y_test_hard, Y_pred_hard)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_confusion_matrix(cnf_matrix, classes=[0,1,2,4,5],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Deep CNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelDeep(input_shape, classes):\n",
    "    \"\"\" \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns: \n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 18,\n",
    "                    kernel_size=(11,11),\n",
    "                    strides=(1,1),\n",
    "                    padding='same',\n",
    "                    input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                          strides=2,\n",
    "                          padding='same'))\n",
    "    \n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv2D(filters = 36,\n",
    "                    kernel_size=(5,5),\n",
    "                    strides=(1,3),\n",
    "                    padding='same',\n",
    "                    input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                          strides=2,\n",
    "                          padding='same'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(filters = 72,\n",
    "              kernel_size=(1,5),\n",
    "              strides=(1,3),\n",
    "              padding='same',\n",
    "              input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                          strides=2,\n",
    "                          padding='same'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #model.add(LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True))\n",
    "    \n",
    "    model.add(Dense(64, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape of the input to \"Flatten\" is not fully defined (got (None, 1, 72). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-3a225a5d8f9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelDeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-dd46e5a85c1c>\u001b[0m in \u001b[0;36mModelDeep\u001b[1;34m(input_shape, classes)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m#model.add(LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    520\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[0;32m    521\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;31m# Inferring the output shape is only relevant for Theano.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m                 \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    497\u001b[0m             raise ValueError('The shape of the input to \"Flatten\" '\n\u001b[0;32m    498\u001b[0m                              \u001b[1;34m'is not fully defined '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m                              \u001b[1;34m'(got '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m                              \u001b[1;34m'Make sure to pass a complete \"input_shape\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m                              \u001b[1;34m'or \"batch_input_shape\" argument to the first '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The shape of the input to \"Flatten\" is not fully defined (got (None, 1, 72). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."
     ]
    }
   ],
   "source": [
    "model_temp = ModelDeep((1,window_size,features), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt4 = Adam(lr=0.01)\n",
    "model_temp.compile(optimizer = opt4, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "# need to reshape in order to fit to the new 2D model\n",
    "X_train = X_train_s.reshape(X_train_s.shape[0], 1, window_size, features)\n",
    "X_test = X_test_s.reshape(X_test_s.shape[0], 1, window_size, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3141 samples, validate on 1149 samples\n",
      "Epoch 1/15\n",
      "3141/3141 [==============================] - 71s 23ms/step - loss: 0.4944 - acc: 0.8214 - val_loss: 0.5066 - val_acc: 0.8529\n",
      "Epoch 2/15\n",
      "3141/3141 [==============================] - 90s 28ms/step - loss: 0.5042 - acc: 0.8150 - val_loss: 0.4951 - val_acc: 0.8668\n",
      "Epoch 3/15\n",
      "3141/3141 [==============================] - 81s 26ms/step - loss: 0.4707 - acc: 0.8348 - val_loss: 0.4502 - val_acc: 0.8834\n",
      "Epoch 4/15\n",
      "3141/3141 [==============================] - 81s 26ms/step - loss: 0.4534 - acc: 0.8316 - val_loss: 0.5085 - val_acc: 0.8547\n",
      "Epoch 5/15\n",
      "3141/3141 [==============================] - 81s 26ms/step - loss: 0.4324 - acc: 0.8424 - val_loss: 0.5627 - val_acc: 0.8312\n",
      "Epoch 6/15\n",
      "3141/3141 [==============================] - 79s 25ms/step - loss: 0.4287 - acc: 0.8526 - val_loss: 0.4550 - val_acc: 0.8825\n",
      "Epoch 7/15\n",
      "3141/3141 [==============================] - 76s 24ms/step - loss: 0.4186 - acc: 0.8523 - val_loss: 0.4876 - val_acc: 0.8547\n",
      "Epoch 8/15\n",
      "3141/3141 [==============================] - 72s 23ms/step - loss: 0.3945 - acc: 0.8634 - val_loss: 0.4939 - val_acc: 0.8573\n",
      "Epoch 9/15\n",
      "3141/3141 [==============================] - 81s 26ms/step - loss: 0.4426 - acc: 0.8376 - val_loss: 0.6748 - val_acc: 0.8155\n",
      "Epoch 10/15\n",
      "3141/3141 [==============================] - 82s 26ms/step - loss: 0.3860 - acc: 0.8647 - val_loss: 0.5067 - val_acc: 0.8477\n",
      "Epoch 11/15\n",
      "3141/3141 [==============================] - 81s 26ms/step - loss: 0.3725 - acc: 0.8625 - val_loss: 0.5005 - val_acc: 0.8451\n",
      "Epoch 12/15\n",
      "3141/3141 [==============================] - 93s 30ms/step - loss: 0.3721 - acc: 0.8714 - val_loss: 0.5286 - val_acc: 0.8529\n",
      "Epoch 13/15\n",
      "3141/3141 [==============================] - 89s 28ms/step - loss: 0.3815 - acc: 0.8695 - val_loss: 0.4993 - val_acc: 0.8555\n",
      "Epoch 14/15\n",
      "3141/3141 [==============================] - 81s 26ms/step - loss: 0.3561 - acc: 0.8717 - val_loss: 0.4894 - val_acc: 0.8590\n",
      "Epoch 15/15\n",
      "3141/3141 [==============================] - 82s 26ms/step - loss: 0.3549 - acc: 0.8816 - val_loss: 0.5092 - val_acc: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d29370f358>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_temp.fit(x = X_train, y = Y_train_s, epochs = 15, batch_size = 128, validation_data=(X_test, Y_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-measure:  0.8529180840387727\n",
      "AUC w.r. to each class:  {0: 0.9728196522150954, 1: 0.9725484922849363, 2: 0.9565779173622311, 3: 0.9908154327424401, 4: 0.8632455779514603}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d295c56470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred_s = model_temp.predict(X_test)\n",
    "\n",
    "# print results\n",
    "#reverse the one-ot encoder procedure\n",
    "Y_test_hard = np.argmax(Y_test_s, axis=1)\n",
    "Y_pred_hard = np.argmax(Y_pred_s, axis=1)\n",
    "\n",
    "print(\"F1-measure: \", utils.f1_score(Y_test_hard, Y_pred_hard, average='weighted'))\n",
    "print(\"AUC w.r. to each class: \", utils.AUC(Y_test_s, Y_pred_s, 5))\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cnf_matrix = utils.confusion_matrix(Y_test_hard, Y_pred_hard)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_confusion_matrix(cnf_matrix, classes=[0,1,2,4,5],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
