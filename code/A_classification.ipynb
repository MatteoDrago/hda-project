{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDA - Project 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import deeplearning\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.activations import relu\n",
    "from keras.layers import Conv2D, BatchNormalization, Dropout, LeakyReLU, Flatten, Activation, Dense, MaxPooling2D, LSTM, Reshape\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the hyper-parameters that can be tuned for code execution:\n",
    "- subject: select the subject on which to test the model, between [1,4];\n",
    "- folder: directory name where '.mat' files are stored;\n",
    "- label_col: column of features to be selected to perform activity detection, between [0,6]:\n",
    "\n",
    "|  Label |  Feature |\n",
    "|:-:     |:-:|\n",
    "|  0     | Locomotion (TASK A)  |\n",
    "|  1     | High Level Activity |\n",
    "|  2     | Low Level Left Arm  |\n",
    "|  3     | Low Level Left Arm Object  |\n",
    "|  4     | Low Level Right Arm  |\n",
    "|  5     | Low Level Right Arm Object  |\n",
    "|  6     | Medium Level Both Arms (TASK B2) |\n",
    "\n",
    "- window_size: parameter that sets the length of temporal windows on which to perform the convolution;\n",
    "- stride: step length to chose the next window.\n",
    "\n",
    "The size of the temporal window seems to be fundamental in order to get a more specific and powerful model; of course the choice of the step lenght between consequent windows has to be consistent and to make sense. Thinking about a real-time situation, as long as we collect data we can use a sliding window of real-time samples; in this way, it is reasonable to use also a small value for the stride. Another important reason behind the choice of the value of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [1,2,3,4]\n",
    "folder = \"./data/full/\"\n",
    "#folder = \"/floyd/input/hdadataset/full/\" # To be used with FloydHub\n",
    "label = 0     # default for task A\n",
    "window_size = 64\n",
    "stride = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "After the _detection_ step, this time we exclude all the samples associated to the _null class_; in this way we can build a neural network cleaned of the null class and that can distinguish better the difference between motions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition, compilation and input reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 110 #number of features taken into consideration for the solution of the problem\n",
    "n_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_7 (Batch (None, 64, 110, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 54, 110, 50)       600       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 54, 110, 50)       200       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 44, 110, 25)       13775     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 22, 110, 25)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 22, 110, 25)       100       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 22, 2750)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 22, 300)           3661200   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 4,553,243\n",
      "Trainable params: 4,553,091\n",
      "Non-trainable params: 152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = deeplearning.MotionClassification((window_size,n_features,1), n_classes)\n",
    "classification_model.summary() # model visualization\n",
    "\n",
    "classification_model.compile(optimizer = Adam(lr=0.01), \n",
    "                   loss = \"categorical_crossentropy\", \n",
    "                   metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting\n",
    "\n",
    "After the training procedure, the model will be saved on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in subjects:\n",
    "    \n",
    "    print(\"Going for USER \", s)\n",
    "    \n",
    "    [x_train, y_train, x_test, y_test, n_classes] = utils.preprocessing(s,\n",
    "                                                                    folder,\n",
    "                                                                    label,\n",
    "                                                                    window_size,\n",
    "                                                                    stride,\n",
    "                                                                    null_class = False)\n",
    "    \n",
    "    input_train = x_train.reshape(x_train.shape[0], window_size, n_features, 1)\n",
    "    input_test = x_test.reshape(x_test.shape[0], window_size, n_features, 1)\n",
    "    \n",
    "    classification_model.fit(x = input_train, \n",
    "                   y = y_train, \n",
    "                   epochs = 20, \n",
    "                   batch_size = 300,\n",
    "                   verbose = 1,\n",
    "                   validation_data=(input_test, y_test))\n",
    "\n",
    "classification_model.save('./classification_model_A.h5')\n",
    "classification_model.save_weights('./classification_model_weights_A.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_model = load_model('./data/classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_test = classification_model.predict(input_test)\n",
    "prediction = np.argmax(output_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Accuracy: \", accuracy_score(np.argmax(y_test, axis=1), prediction))\n",
    "print(\"F1-measure: \", utils.f1_score(np.argmax(y_test, axis=1), prediction, average='weighted'))\n",
    "\n",
    "cnf_matrix = utils.confusion_matrix(np.argmax(y_test, axis=1), prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "plt.figure()\n",
    "utils.plot_confusion_matrix(cnf_matrix, classes=[1,2,4,5],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
