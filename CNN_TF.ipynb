{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scipy.io.loadmat(\"data_temp/S1-ADL1\", mdict={'filled_features':'features', 'labels':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -43.,  971., -339., ...,   29.,  -24.,  165.],\n",
       "       [ -33.,  957., -347., ...,    5.,  -33.,  165.],\n",
       "       [ -35.,  966., -363., ...,   32.,   47.,  165.],\n",
       "       ...,\n",
       "       [-313.,  905.,  656., ...,   15.,  -44.,  -76.],\n",
       "       [-232.,  959.,  695., ...,   19.,  -10.,  -76.],\n",
       "       [  -9.,  950.,  791., ...,    2.,   70.,  -76.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['filled_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [2, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size, seq_length, n_channels = 1, 50, 113\n",
    "stride = 25\n",
    "activity_label = 1\n",
    "labels = labels_all.iloc[:,activity_label]\n",
    "\n",
    "print(\"\\nBatch size: \", batch_size, \"\\nSequence length: \", seq_length)\n",
    "print(\"\\nLabels:\\n\", labels.head())\n",
    "\n",
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, shape=[None, seq_length, n_channels], name='input')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name='label')\n",
    "\n",
    "# layers\n",
    "conv_1 = tf.layers.conv1d(inputs=X, filters=64, kernel_size=2, activation=tf.nn.relu)\n",
    "max_pool_1 = tf.layers.max_pooling1d(inputs=conv_1, pool_size=2, strides=2, padding='same')\n",
    "dropout_1 = tf.layers.dropout(inputs=max_pool_1, rate=0.3)\n",
    "\n",
    "conv_2 = tf.layers.conv1d(inputs=dropout_1, filters=36, kernel_size=1, activation=tf.nn.relu)\n",
    "max_pool_2 = tf.layers.max_pooling1d(inputs=conv_2, pool_size=2, strides=2, padding='same')\n",
    "dropout_2 = tf.layers.dropout(inputs=max_pool_2, rate=0.3)\n",
    "\n",
    "full_1 = tf.layers.dense(inputs=dropout_2, units=10)\n",
    "\n",
    "y_pred = tf.layers.dense(inputs=full_1, units=4)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_pred))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# session\n",
    "def next_batch(step, seq_length, batch_size):\n",
    "    idx_from = step * stride\n",
    "    batch_x = features_all[idx_from:idx_from+seq_length]\n",
    "    batch_y = labels_all[idx_from:idx_from+seq_length]\n",
    "    # use histogram to select a unique lable\n",
    "    batch_y = batch_y[1,1]\n",
    "\n",
    "    return batch_x, batch_y\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "steps = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x, batch_y = next_batch(i, seq_length, batch_size)\n",
    "        \n",
    "        sess.run(train, feed_dict={X:batch_x, y:batch_y})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={X:batch_x, y:batch_y}))\n",
    "            print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
