% !TEX root = HDA_MDRL.tex

\section{Concluding Remarks}
\label{sec:conclusions}

In our project we realized from scratch two different pipelines to perform activity recognition. A comparison between the two is carried out using different models, which are inspired to the best ones in the literature. This helped us understanding that there isn't a clear best choice from an accuracy point of view: splitting the pipeline into a cascade of detection and classification unexpectedly didn't seem to improve much the accuracy of the final classification; still, it might be desirable to design a recognition system in this way because of power consumption constraints, as discussed in \ref{sec:learning_framework}.

The most limiting factor for the performances of our models has been the class imbalance. Throughout our experiments we found out that there was a huge difference in accuracy when including or excluding the \textit{dominant}, i.e. most present, class: in the case of gesture recognition in fact, the dominant class is the one representing \textit{inactivity}, which if not considered, as in our "\textit{Activity Classification}" model, leads to poorer results; in the case of locomotion classification instead, neglecting the \textit{Null} class improved the performances because it isn't the dominant class in this case, which is \textit{Standing} instead.
To try tackling this problem, we first performed the training of our models using a loss function inversely weighted with respect to the fraction of samples of each label, in such a way to give more importance to under-represented classes: this didn't improve our results because still the training was performed in an unbalanced set. Then we tried also to augment the dataset during preprocessing by adding redundancy: replicating the instances of the under-represented classes we obtained a larger set on which each label had the same number of instances. Unfortunately, neither this method worked: results in fact didn't improve nor decrease. To solve this issue then it would be better to resort to more complex solutions, as the one presented in \cite{cao2012integrated}.
We hypothesise that once the class imbalance problem is solved, performances should be better, favouring in particular the \textit{Cascade Classification} approach. This is left though for future work, together with a mathematical analysis of how the errors in the \textit{Cascade} add up.

This project was very helpful to us because we actually learned to code in python, we had to face different obstacles and learned that results are never what one would expect: we hoped in better results, for the advanced techniques used, and expected similar networks to have almost equal performances, which wasn't always the case.