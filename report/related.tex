% !TEX root = template.tex

\section{Related Work}
\label{sec:related_work}
The OPPORTUNITY activity recognition dataset has been introduced in \cite{ComplexAct-2010} to overcome the lack of an evaluation setup, to compare different classification systems and to provide a more exhaustive dataset compared to the others, which \RL{citazione} "are not sufficiently rich to investigate opportunistic activity recognition, where a high number of sensors is required on the body, in objects and in the environment, with a high number of activity instances". As pointed out in \cite{Chavarriaga2013} in fact, previously, several datasets were related to the activities which were to be classified: this is due to researchers acquiring signals only from sensors located in specific locations, according to the task of interest.
To overcome this drawback, the OPPORTUNITY dataset has been gathered from a monitored, sensor rich environment: objects from the scene were connected to acquisition sensors, while people participating to the session were equipped with on-body sensors; signals collected from the latter type of measurement units will be described in section \ref{sec:model}. This particular dataset has been fundamental over the past years, it provided indeed an heterogeneous and complete set of time series, perfectly suitable for different studies in the HAR domain. In \cite{Chavarriaga2013} they presented it as a \textit{benchmarking dataset}: as a demonstration, they provided the results obtained with four classification techniques (\textit{k-nearest neighbours, nearest centroid, linear discriminant analysis, quadratic discriminant analysis}) and they compared them with some other contributed models. Since our analysis is based on this dataset, to make the discussion consistent we introduce a collection of interesting works that use the same dataset for their evaluation.

The authors in \cite{cao2012integrated} propose an exhaustive framework which, besides the standard preprocessing on the activity data sequence, e.g. filling of the gaps via interpolation and data normalization, presents also a solution for the well-known class imbalance problem \cite{japkowicz2002class}. Moreover, they also include a post-processing procedure after classification, consisting of a smoothing operation along the temporal axis and of a strategic fusion procedure to integrate prediction sequences from different classifiers, in order to reduce the risk of making an erroneous classification. The classifiers used in this work consisted in a 1-layer neural network (1NN) and a Support Vector Machine (SVM, complete overview of this tool in \cite{hearst1998support}). 

We can see an example of CNN applied to HAR in \cite{yang2015deep} where, in order to evaluate their model, they use also the Hand Gesture dataset \cite{bulling2014tutorial}. In this configuration the authors designed a network with three consecutive convolutional blocks; the first two are constituted by a convolutional layer, a rectified linear unit layer (ReLU) and a max pooling layer. The latter instead is constituted of a convolutional layer followed by a ReLU and a normalization layer. The reason behind this collection of layers is that, while the first ones identify \textit{basic} movements in human activity, higher layers characterize the combination of these basic movements. At the end of these core blocks, two fully-connected layers are added in order to complete the classification structure. It's important to notice also that here a sliding window strategy has been adopted to segment the time series: in this way the prediction is not focused on a single sample but is associated to a temporal matrix; the corresponding label is determined by the most-frequent label among the matrix of samples.

As a form of regularization, in \cite{hammerla2016deep} the authors add to the CNN also a dropout layer (more on this technique in \cite{srivastava2014dropout}); moreover, they also put together a recurrent neural network in order to exploit time dependencies between different windows \RL{nell'abstract sono samples, dobbiamo decidere}. In particular, they built two flavours of LSTM networks: one that contains multiple layers of recurrent units connected forward in time, and another which exploits dependencies either backward and forward with respect to the time-step of interest. This last configuration in particular gives the best results when applied to the OPPORTUNITY dataset in terms of F1-measure.

In conclusion, recent work in \cite{li2018comparison} provides a complete comparison among different features extraction and classification techniques; first, they demonstrate how the method of hand-crafted features gives poor results with respect to deep learning mechanism. Then, they make a step forward with respect to the work in \cite{hammerla2016deep} as they create an hybrid architecture, comprehensive of both convolutional and a recurrent LSTM layers. In this way they exploit correlation among samples of a single window (as in \cite{yang2015deep}), searching for significant features; also, with LSTM they exploit correlation in time among independent windows. This combination results in a slight improvement with respect to those configurations where CNN and LSTM layers are not implemented jointly.

In our work we implement this hybrid model, introduced in \cite{li2018comparison} \RL{controllare che sia la ref giusta}, and some others, varying the number of layers. These models are then tested in different types of tasks and compared.