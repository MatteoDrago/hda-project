% !TEX root = template.tex

\section{Related Work}
\label{sec:related_work}
The \textbf{OPPORTUNITY} activity recognition dataset has been introduced in \cite{ComplexAct-2010} to overcome the lack of an evaluation setup, to compare different classification systems and to provide a more exhaustive dataset compared to the others, which "are not sufficiently rich to investigate opportunistic activity recognition, where a high number of sensors is required on the body, in objects and in the environment, with a high number of activity instances". As pointed out in \cite{Chavarriaga2013} in fact, previously, several datasets were related to the activities which were to be classified: this is due to researchers acquiring signals only from sensors located in specific locations, according to the task of interest.
To overcome this drawback, the \textbf{OPPORTUNITY} dataset has been gathered from a monitored, sensor rich environment \MD{aggiungere img dell'ambiente?} : objects from the scene were connected to acquisition sensors, while people participating to the session were equipped with on-body sensors\MD{; signals collected from different sensors will be described in section \ref{sec:model}}. This particular dataset has been fundamental over the past years, it provided indeed an heterogeneous and complete set of time series, perfectly suitable for different studies in the \textbf{HAR} domain. In \cite{Chavarriaga2013} they present it as a \textit{benchmark dataset}; as a demonstration, they provide the results obtained with four classification techniques (\textit{k-nearest neighbours, nearest centroid, linear discriminant analysis, quadratic discriminant analysis}) and they compare them with other works that used the same dataset. \MD{inseriamo anche i valori che ottengono nel paper per confronto?}

Given that we had to perform our elaboration on this dataset, in order to make the discussion consistent in the following we introduce a collection of interesting works that use the same dataset (and others, when available) for their evaluation.

The authors in \cite{cao2012integrated} proposed an exhaustive framework which, besides the standard preprocessing on the activity data sequence (filling of the gaps via interpolation and data normalization), presents also a solution for the well-known class imbalance problem \cite{japkowicz2002class}. Moreover, they also include a post-processing procedure after classification consisting of a smoothing operation along the temporal axis \MD{(i dati non vengono finestrati e quindi loro li filtrano)} and of a strategic fusion procedure to integrate prediction sequences from different classifiers, in order to reduce the risk of making an erroneous classification. The classifiers used in this work consisted in a 1-layer neural network (1NN) and a Support Vector Machine (SVM, complete overview of this tool in \cite{hearst1998support}). 

We can see an example of CNN applied to HAR in \cite{yang2015deep} where, in order to evaluate their model, they use also the Hand Gesture dataset \cite{bulling2014tutorial}. In this configuration the authors designed a network with three consecutive convolutional blocks; the first two are constituted by a convolutional layer, a rectified linear unit layer (ReLU) and a max pooling layer. The latter instead is constituted of a convolutional layer followed by a ReLU and a normalization layer. The reason behind this collection of layers is that, while the first ones identify \textbf{basic} movements in human activity, higher layers characterize the combination of these basic movements. At the end of these core blocks, two fully-connected layers are added in order to complete the classification structure. It's important to notice also that here a sliding window strategy has been adopted to segment the time series: in this way the prediction is not focused on a single sample but is associated to a temporal matrix; the corresponding label is determined by the most-frequent label among the matrix of samples.

As a form of regularization, in \cite{hammerla2016deep} the authors added to the CNN also a dropout layer (more on this technique in \cite{srivastava2014dropout}); moreover, they also put together a recurrent neural network in order to exploit time dependencies between different windows. In particular, they built two flavours of LSTM networks: one that contains multiple layers of recurrent units connected forward in time, and another which exploit dependencies either backward and forward with respect to the time-step of interest. These last configuration in particular gave the best results when applied to the \textbf{OPPORTUNITY} dataset. \MD{(dovremmo scrivere anche "in termini di f1-measure"? pi√π che altro non l'abbiamo ancora introdotta)} 

In conclusion, the recent work in \cite{li2018comparison} provided a complete comparison among different features extraction and classification techniques; first, they demonstrated how the method of hand-crafted features give poor results with respect to deep learning mechanism. Then, they made a step forward with respect to the work in \cite{hammerla2016deep} as they created an hybrid architecture comprehensive of both a convolutional and a recurrent LSTM layer. In this way they exploited correlation among samples of a single window (as in \cite{yang2015deep}), searching for significant features; also, with LSTM they exploit correlation in time among independent windows. This combination results in a slight improvement with respect to the configurations when CNN and LSTM layers are not implemented jointly.

Again, in our work