% !TEX root = template.tex

\section{Introduction}
\label{sec:introduction}

During the past decade, time series classification has captured growing interest thanks to the introduction of deep learning mechanisms, such as neural networks. These tools indeed are capable of identify and learn signal features, which are then exploited for classification, without the need of human domain-knowledge: this is a huge step forward considering that features were traditionally hand-crafted.\MD{[non trovo nessuna reference per questo]}
Human Activity Recognition (HAR) in particular has been fostered by the spread of powerful, efficient and affordable sensors, which nowadays are commonly found in mobile phones and wearable devices, with multiple applications, ranging from health care to gaming and virtual reality. \cite{HAR-2013}
Wearable sensors allow us to collect and process a huge amount of signals, which are essential for deep neural networks (DNN) to work properly: in fact, in order for them to learn and being accurate enough to be preferred over standard machine learning approaches, we need the input training set to be heterogeneous, meaningful and representative of the problem.

For this reason, HAR is not an easy classification problem: when dealing with on-body sensors, system performances heavily depends on human behaviour, which is a source of high variability; moreover, data collected from sensors is typically high-dimensional, multi-modal and subjected to noise, making the problem even more difficult from a machine learning perspective. 
In the recent years, several models to perform activity detection and classification have been proposed, but as pointed out in \cite{Chavarriaga2013} and \cite{HAR-COMP2018}, the lack of a baseline evaluation and of structured and fixed implementation details prevented a fair comparison between different solutions.

Considering that many authors in the field of machine learning and activity recognition tried to solve these problems, after an accurate study of the state of the art we decided to focus on recent works and to start from them in order to study and design improvements to the framework. Our aim was to find an architecture which gives comparable (and possibly better) performances while minimizing the number of trainable parameters and the assortment of layers in the network. The reason why we decided to go down this path is that in the literature they usually tend to expand the power of the network via increasing the computational complexity, adding layers over layers with the hope that the more number of layers, the more accurate the model. However, specifically when dealing with real time application, computational power is limited and the possibility of using difficult models is far from being realizable. \MD{[forse andrebbe messa qualche citazione, ma non ne trovo nessuna di specifica]}
As a first step towards the exemplification of the architecture, we decided to design two distinct networks: one dedicated to detect movements, consisting of \MD{da aggiungere descrizione del modello che decideremo}; the other instead created with the purpose of classifying the movement, when detected, in this case built as \MD{da aggiungere descrizione del modello che decideremo}. Then, we compare the performances of this cascade-model with a classification system that comprehends also the \textbf{Null Class} which in our case represents the state of \textbf{no activity}. With our study we aim also to provide a baseline for future works, exploiting this two-steps technique for reducing computational complexity. In order to assess the efficiency of our models, we used the \textbf{OPPORTUNITY} dataset \cite{Chavarriaga2013, ComplexAct-2010} which will be described in details in the following sections.

In conclusion, the contributions of this paper are:
\begin{itemize}
	\item overview of the latest progresses of the state of the art 
	\item implementation of these solution for comparison purpose
	\item the design of two separated pipelines for reducing complexity. 
\end{itemize}
 
The paper is organized as follow: section \RomanNumeralCaps{2} provides a summary of the latest and more important works related to our studies; in section \RomanNumeralCaps{3} we start delving into the details of how we organized our HAR architecture, step by step; section \RomanNumeralCaps{4} is dedicated to the description of the dataset and to the decisions we made in the preprocessing phase; finally in section \RomanNumeralCaps{5} we are ready to describe meticulously the learning framework, while sections \RomanNumeralCaps{6} and \RomanNumeralCaps{7} are for discussion of results and for drawing our conclusions. 