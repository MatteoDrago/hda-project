% !TEX root = template.tex

\section{Processing Pipeline}
\label{sec:processing_architecture}

We start off our analysis by preprocessing the collected signals within the MATLAB environment: we chose that framework because we find it is easier to operate with matrices. In this first step we import the data collected by sensors, which are given as .dat files, then we select the signals from on-body sensors and discard the others, so we replace the missing values by means of interpolation and, at last, we store them as .mat files.

Secondly, we import the preprocessed data in a \textit{Jupyter Notebook} and make the dataset suitable for the classification task: this consists for example of segmenting data into windows, scaling and normalizing raw signals.

Then, after the last step of preprocessing, we define and train a suitable learning model. This is respectively done for both the locomotion activity and gestures recognition, i.e. with two different sets of labels. This system, which is forced to learn also the null class together with the actual movements, is then compared to a different system where two models are deployed: in that case, the first one has the purpose of detecting activity while the second one classifies the type of movement, if detected. \MD{Aggiungere figura pipeline?}

\section{Signals and Features}
\label{sec:model}

The \textbf{OPPORTUNITY} dataset, succinctly introduced in section \ref{sec:related_work}, has been collected from four subjects accomplishing different Activities of Daily Life (ADLs). As highlighted before, both the subjects and the environment they moved in were meticulously monitored.
The process of acquisition consisted in 5 consecutive runs (named ADL1 to ADL5) that followed a predetermined script, plus a sixth run consisting of 20 repetitions of each of the distinct discrete activity present in the script. Then each vector of samples corresponding to a single time-step is labelled; in the following we'll refer to Task A when we consider an high-level motion classification (\textit{Standing, Walking, Sittin, Lying}) while we'll refer to Task B2 for a more detailed and specific movement detection (\MD{Inserire lista 17 classi}).

The wireless sensors worn by the subjects (IMU - Inertial Measurement Unit) provided acceleration among the three-axes, rate of turn, magnetic field and orientation information; in addition, 12 accelerometers were placed on the subjects' parts of the body sensible to movements (arms, back, hips and feet). All these sensors for a total of 145 distinct acquired channels. \MD{Aggiungere immagine ometti con sensori?}

For the purposes of our work, however, we based the analysis only on on-body sensor signals using just a subset of the available sensors: in this way, we ended up with a total of 113 channels. Another important point is that in the preprocessing phase we performed spline interpolation (which uses a cubic polynomial) in channels that manifested missing data (equivalent to a NaN vale); however, this type of interpolation ends up meaningless if more than the 30\% of data is missing. For this reason we had to discard all the three columns corresponding to one of the physical devices: finally, this led us to work with 110 channels.

Since we noticed that the head and the tail of the measurement sessions correspond to a transient where most of the sensors are turned-off, we decided to discard them. In this way we ensure that the interpolation phase provides consistent results.

Then, to perform classification on the data of one subject, we stacked sessions ADL 1 to 3 and Drill to create our training set, and then ADL4 and ADL5 as test set. In some cases, interpolation leaves entire columns to NaN because it isn't provided any data to interpolate those values. We solved the problem by setting to 0 those entire columns.

Subsequently we scaled the signals by subtracting their means and dividing by their variance (or sigma?). After this, data is shaped into windows of 15 samples (500 ms) with a stride of 5 samples. The approach that we used to segment the data was then the sliding window introduced above. To perform classification, though we had to assign to each window a unique label, which we decided to be corresponding to the label present with more samples. This doesn't constitute a problem per se, even when changing the size of the sliding window, as long as it is kept short enough and ...


\section{Learning Framework}
\label{sec:learning_framework}


One of the main problems in Human Activity Recognition is handling \text{inactivity}.

Thinking of a real recognition system, 
In this paper we compare two different learning strategies, mimicking a real system. In the first \ref{sub:oneshot}, \text{One Shot Classification}, the model is trained to learn a representation of the involved classes together with the null class

\subsection{One Shot Classification}
\label{sub:oneshot}

\subsection{Two Steps Classification}
\label{sub:twosteps}
