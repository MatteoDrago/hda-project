@article{HAR-2013,
	author={O. D. Lara and M. A. Labrador},
	journal={IEEE Communications Surveys Tutorials},
	title={A Survey on Human Activity Recognition using Wearable Sensors},
	year={2013},
	volume={15},
	number={3},
	pages={1192-1209},
	keywords={image motion analysis;learning (artificial intelligence);mobile computing;wearable computers;human activity recognition;wearable sensors;pervasive computing;mobile devices;two-level taxonomy;semi-supervised learning;response time;recognition performance;energy consumption;open problems;Feature extraction;Accelerometers;Pervasive computing;Wearable sensors;Human-centric sensing;machine learning;mobile applications;context awareness},
	doi={10.1109/SURV.2012.110112.00192},
	ISSN={1553-877X},
	month={Third},}

@article{Chavarriaga2013,
	author = {Chavarriaga, Ricardo and Sagha, Hesam and Calatroni, Alberto and Digumarti, Sundara Tejaswi and Tr{\"{o}}ster, Gerhard and del R. Mill{\'{a}}n, Jos{\'{e}} and Roggen, Daniel},
	keywords = {OPPORTUNITY},
	title = {The Opportunity challenge: A benchmark database for on-body sensor-based activity recognition},
	journal = {Pattern Recognition Letters},
	year = {2013},
	doi = {10.1016/j.patrec.2012.12.014},
	abstract = {There is a growing interest on using ambient and wearable sensors for human activity recognition, fostered by several application domains and wider availability of sensing technologies. This has triggered increasing attention on the development of robust machine learning techniques that exploits multimodal sensor setups. However, unlike other applications, there are no established benchmarking problems for this field. As a matter of fact, methods are usually tested on custom datasets acquired in very specific experimental setups. Furthermore, data is seldom shared between different groups. Our goal is to address this issue by introducing a versatile human activity dataset recorded in a sensor-rich environment. This database was the basis of an open challenge on activity recognition. We report here the outcome of this challenge, as well as baseline performance using different classification techniques. We expect this benchmarking database will motivate other researchers to replicate and outperform the presented results, thus contributing to further advances in the state-of-the-art of activity recognition methods.}
}


@article{HAR-COMP2018,
	AUTHOR = {Li, Frédéric and Shirahama, Kimiaki and Nisar, Muhammad Adeel and Köping, Lukas and Grzegorzek, Marcin},
	TITLE = {Comparison of Feature Learning Methods for Human Activity Recognition Using Wearable Sensors},
	JOURNAL = {Sensors},
	VOLUME = {18},
	YEAR = {2018},
	NUMBER = {2},
	ARTICLE NUMBER = {679},
	URL = {http://www.mdpi.com/1424-8220/18/2/679},
	ISSN = {1424-8220},
	ABSTRACT = {Getting a good feature representation of data is paramount for Human Activity Recognition (HAR) using wearable sensors. An increasing number of feature learning approaches?in particular deep-learning based?have been proposed to extract an effective feature representation by analyzing large amounts of data. However, getting an objective interpretation of their performances faces two problems: the lack of a baseline evaluation setup, which makes a strict comparison between them impossible, and the insufficiency of implementation details, which can hinder their use. In this paper, we attempt to address both issues: we firstly propose an evaluation framework allowing a rigorous comparison of features extracted by different methods, and use it to carry out extensive experiments with state-of-the-art feature learning approaches. We then provide all the codes and implementation details to make both the reproduction of the results reported in this paper and the re-use of our framework easier for other researchers. Our studies carried out on the OPPORTUNITY and UniMiB-SHAR datasets highlight the effectiveness of hybrid deep-learning architectures involving convolutional and Long-Short-Term-Memory (LSTM) to obtain features characterising both short- and long-term time dependencies in the data.},
	DOI = {10.3390/s18020679}
}

@article{japkowicz2002class,
	title={The class imbalance problem: A systematic study},
	author={Japkowicz, Nathalie and Stephen, Shaju},
	journal={Intelligent data analysis},
	volume={6},
	number={5},
	pages={429--449},
	year={2002},
	publisher={IOS Press}
}

@article{hearst1998support,
	title={Support vector machines},
	author={Hearst, Marti A. and Dumais, Susan T and Osuna, Edgar and Platt, John and Scholkopf, Bernhard},
	journal={IEEE Intelligent Systems and their applications},
	volume={13},
	number={4},
	pages={18--28},
	year={1998},
	publisher={IEEE}
}

@article{bulling2014tutorial,
	title={A tutorial on human activity recognition using body-worn inertial sensors},
	author={Bulling, Andreas and Blanke, Ulf and Schiele, Bernt},
	journal={ACM Computing Surveys (CSUR)},
	volume={46},
	number={3},
	pages={33},
	year={2014},
	publisher={ACM}
}

@article{hammerla2016deep,
	title={Deep, convolutional, and recurrent models for human activity recognition using wearables},
	author={Hammerla, Nils Y and Halloran, Shane and Ploetz, Thomas},
	journal={arXiv preprint arXiv:1604.08880},
	year={2016}
}

@article{srivastava2014dropout,
	title={Dropout: a simple way to prevent neural networks from overfitting},
	author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal={The Journal of Machine Learning Research},
	volume={15},
	number={1},
	pages={1929--1958},
	year={2014},
	publisher={JMLR. org}
}

@article{li2018comparison,
	title={Comparison of Feature Learning Methods for Human Activity Recognition Using Wearable Sensors},
	author={Li, Fr{\'e}d{\'e}ric and Shirahama, Kimiaki and Nisar, Muhammad Adeel and K{\"o}ping, Lukas and Grzegorzek, Marcin},
	journal={Sensors},
	volume={18},
	number={2},
	pages={679},
	year={2018},
	publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{cao2012integrated,
	title={An integrated framework for human activity classification.},
	author={Cao, Hong and Nguyen, Minh Nhut and Phua, Clifton and Krishnaswamy, Shonali and Li, Xiaoli},
	booktitle={UbiComp},
	pages={331--340},
	year={2012}
}

@inproceedings{yang2015deep,
	title={Deep Convolutional Neural Networks on Multichannel Time Series for Human Activity Recognition.},
	author={Yang, Jianbo and Nguyen, Minh Nhut and San, Phyo Phyo and Li, Xiaoli and Krishnaswamy, Shonali},
	booktitle={Ijcai},
	volume={15},
	pages={3995--4001},
	year={2015}
}

@inproceedings{ComplexAct-2010, 
	author={D. Roggen and A. Calatroni and M. Rossi and T. Holleczek and K. Förster and G. Tröster and P. Lukowicz and D. Bannach and G. Pirkl and A. Ferscha and J. Doppler and C. Holzmann and M. Kurz and G. Holl and R. Chavarriaga and H. Sagha and H. Bayati and M. Creatura and J. d. R. Millàn}, 
	booktitle={2010 Seventh International Conference on Networked Sensing Systems (INSS)}, 
	title={Collecting complex activity datasets in highly rich networked sensor environments}, 
	year={2010}, 
	volume={}, 
	number={}, 
	pages={233-240}, 
	keywords={data acquisition;human factors;learning (artificial intelligence);pattern recognition;synchronisation;ubiquitous computing;wireless sensor networks;complex activity dataset;wireless networked sensor system;wired networked sensor system;machine recognition;human activity;sensor data;data acquisition;data synchronization;heterogeneous networked sensor system;machine learning technique;Microphones;Bluetooth;Humidity;Lead;Bismuth;Artificial intelligence;Electrocardiography;Wearable computing;Ubiquitous computing;Human behavior recognition;Machine learning;Pattern classification;Activity recognition dataset}, 
	doi={10.1109/INSS.2010.5573462}, 
	ISSN={}, 
	month={June}
}